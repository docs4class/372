% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={BADM 372 Applied Analytics},
  pdfauthor={BADM 372},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{BADM 372 Applied Analytics}
\author{BADM 372}
\date{2023-01-10}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{about-this-course}{%
\chapter{About this course}\label{about-this-course}}

This website serves as headquarters for \textbf{BADM 372 Applied Analytics}.

Content here will be updated with any changes made during the semester, so if at any point you are told there was a change in the schedule or an assignment, you can come here to get the updated version.

Also, this website has benefited greatly from lots of free, readily available resources posted on the web and we leverage these extensively. I would encourage you to review these resources in your analytics journey. Some that we specifically use with great frequency are these (\textbf{and I say a loud THANK YOU to the authors!}):

\begin{itemize}
\tightlist
\item
  \href{https://r4ds.had.co.nz/}{R for Data Science}
\item
  \href{https://trevorhastie.github.io/ISLR/}{An Introduction to Statistical Learning with Applications in R}
\item
  \href{https://datasciencebox.org/}{Data Science in a Box}
\item
  \href{https://stackoverflow.com/questions/4862178/remove-rows-with-all-or-some-nas-missing-values-in-data-frame?rq=1}{stackoverflow.com, for example}
\end{itemize}

\hypertarget{syllabus}{%
\chapter{Syllabus}\label{syllabus}}

Instructor: Tobin Turner

Office Hours: mutually convenient time arranged by email e-mail: \href{mailto:jtturner@presby.edu}{\nolinkurl{jtturner@presby.edu}}

\hypertarget{course-objectives-and-learning-outcomes}{%
\section{Course Objectives and Learning Outcomes}\label{course-objectives-and-learning-outcomes}}

This course is designed to introduce to data science. Students will apply statistical knowledge and techniques to both business and non-business contexts.

At the end of this course students should be able to:

By the end of the course, you will be able to\ldots{}

\begin{itemize}
\tightlist
\item
  gain insight from data
\item
  gain insight from data, reproducibly
\item
  gain insight from data, reproducibly, using modern programming tools and techniques
\item
  gain insight from data, reproducibly and collaboratively, using modern programming tools and techniques
\item
  gain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques
\item
  communicate results effectively
\end{itemize}

This course will be focused on both understanding and applying key business analytical concepts. Although the text serves as a useful foundation for the concepts covered in the class, simple memorization of the material in the text will not be sufficient. Class participation, discussion, and application are critical.

\hypertarget{text-and-resources}{%
\section{Text and Resources}\label{text-and-resources}}

\begin{itemize}
\tightlist
\item
  This course website (primary resource)
\item
  \href{https://r4ds.had.co.nz/}{R for Data Science}
\item
  \href{https://trevorhastie.github.io/ISLR/}{An Introduction to Statistical Learning with Applications in R}
\item
  \href{https://datasciencebox.org/}{Data Science in a Box}
\item
  \href{https://stackoverflow.com/questions/4862178/remove-rows-with-all-or-some-nas-missing-values-in-data-frame?rq=1}{stackoverflow.com, for example}
\item
  Other free, publicly available datasets and publications.
\end{itemize}

\hypertarget{performance-evaluation-grading}{%
\section{Performance Evaluation (Grading)}\label{performance-evaluation-grading}}

\begin{itemize}
\tightlist
\item
  Labs, Quizzes and Assignments - 40\%
\item
  Exam 1 - 20\%
\item
  Exam 2 - 20\%
\item
  Final Exam - 20\%
\end{itemize}

\hypertarget{missed-examsassignments-zero}{%
\subsection{Missed Exams/Assignments = ZERO}\label{missed-examsassignments-zero}}

Arrangements for missed or late assignments must be made \textbf{PRIOR} to the exam or due date or the student may receive a ZERO grade for the exam or assignment. See attendance and quiz sections below for more details.

\begin{itemize}
\tightlist
\item
  \textbf{Missed Quizzes and Assignments cannot be made up later. Be present.}
\end{itemize}

\hypertarget{exams}{%
\subsection{Exams}\label{exams}}

Exams will cover assigned chapters in the textbook, other assigned readings, lectures, class exercises, class discussions, videos, and guest speakers. I will typically allocate time prior to each exam to clearly identify the body of knowledge each test will cover and to answer questions about the format and objectives of the exam.

\hypertarget{labsquizzes-dont-miss-class}{%
\subsection{\texorpdfstring{Labs/Quizzes -- \textbf{DON'T MISS CLASS}}{Labs/Quizzes -- DON'T MISS CLASS}}\label{labsquizzes-dont-miss-class}}

\begin{itemize}
\tightlist
\item
  The average of all labs, quizzes and assignments will comprise the Quizzes and Assignments - 40\% portion of your final grade
\item
  Quizzes and Assignments are designed to prepare you for your exams and to ensure you stay up with the course material
\item
  \textbf{Missed Quizzes and Assignments cannot be made up later. Be present.}
\end{itemize}

Quizzes rule. \textbf{LISTEN.}
- \textbf{Missed Quizzes and Assignments cannot be made up later. Be present.}

\hypertarget{final-average}{%
\subsection{Final Average}\label{final-average}}

\begin{itemize}
\tightlist
\item
  Final Average Grade

  \begin{itemize}
  \tightlist
  \item
    90-100 A
  \item
    88-89 B+
  \item
    82-87 B+
  \item
    80-81 B-
  \item
    78-79 C+
  \item
    72-77 C+
  \item
    70-71 C-
  \item
    60-69 D
  \item
    59 and below F
  \end{itemize}
\end{itemize}

\hypertarget{class-participation}{%
\section{Class Participation:}\label{class-participation}}

I will frequently give readings or assignments for you to complete prior to the next class meeting. I expect you to fully engage the material: answer questions, pose questions, provide insightful observations. Keep in mind that quality is an important component in ``participation.'' Periodic cold calls will take place. I will also put students in the ``hot seat'' on occasion. In these class sessions, I may select a random group of students to lead us in the discussion and debate. Because the selection of participants will not be announced until class begins, everyone will be expected to prepare for the discussion. Reading the assigned chapters and articles are the best way to prepare for the discussion. If you have concerns about being called on in class, please see me to discuss. The purpose of the ``hot seat'' is not to stress or embarrass students, but to encourage students to actively engage the material.

\hypertarget{phones}{%
\section{Phones}\label{phones}}

\textbf{Phones are not allowed to be used in class without the instructor's prior consent.} If you have a need of a phone during class please let me know before class. Unauthorized use of electronic devices may result in the lowering of the grade or dismissal from the class. \textbf{I mean this.}

\textbf{The phone thing? I mean this.}

\hypertarget{attendance}{%
\section{Attendance}\label{attendance}}

You are expected to be regular and punctual in your class attendance. Students are responsible for all the material missed and homework assignments made. If class is missed, notes/homework should be obtained from another student. If I am more than 15 minutes late, class is considered cancelled. No more than 4 absences are allowed during a semester. Exceeding the absence policy may result in receiving an F for the course. The professors roll is the official roll and students not present when roll is taken will be counted as absent. If a student must miss an exam, she or he must work out an agreeable time with the instructor to take the test prior to the exam being given. If a student misses a test due to an emergency, the student must inform the instructor as soon as is possible. In special cases, the instructor may allow the student to take a make-up exam.

\hypertarget{accommodations}{%
\section{Accommodations}\label{accommodations}}

Presbyterian College is committed to providing reasonable accommodations for all students with documented disabilities. If you are seeking academic accommodations under the Americans with Disabilities Act, you must register with the Academic Success Office, located on 5th Avenue (beside Campus Police). To receive these accommodations, please obtain the proper Accommodations Approval Form from that office, and then meet with me at the beginning of the semester to discuss how we may deliver your approved accommodations. I especially encourage you to meet with me well in advance of the actual accommodations being provided, as it may not be feasible to offer immediate accommodations without sufficient advance notice (such as in the case of tests). I can assure you that all discussions will remain confidential. Disability Services information is located at this link \url{http://bit.ly/PCdisabilityservices}

Additionally, it is the student's responsibility to give the instructor one week's notice prior to each instance where accommodation will be required.

\hypertarget{honor-code-and-plagiarism}{%
\section{Honor Code and Plagiarism:}\label{honor-code-and-plagiarism}}

All assignments/exams must be your own work. Any copying or use of unauthorized assistance will be treated as a violation of PC's Honor Code. If you are unsure of what resources are allowed, please ask. Please note that all text longer than 7 words taken from ANY other source must be placed in quotations and cited. Also, summarizing ANY other source must also be cited. Using ANY other source and showing work to be your own is a violation of plagiarism and the honor code.

\hypertarget{first-generation-version}{%
\section{First-Generation Version:}\label{first-generation-version}}

I am a Presby First+ Advocate. I am here to support our current first-generation students. At Presbyterian College, first-generation students are those in which neither parent nor legal guardian graduated from a four-year higher education institution with a bachelor's degree. If you are a first-generation college student, please contact me. For more information about support for first-generation college students on our campus visit our Presby First+ webpage.

\hypertarget{continuing-advocate-version}{%
\section{Continuing Advocate Version}\label{continuing-advocate-version}}

I am a Presby First+ Advocate. I am committed to supporting first-generation students at Presbyterian College. At Presbyterian College, first-generation students are those in which neither parent nor legal guardian graduated from a four-year higher education institution with a bachelor's degree. If you are a first-generation college student, please contact me anytime or visit me during my office hours. For more information about support for first-generation college students on our campus visit our Presby First+ webpage.

\hypertarget{schedule}{%
\chapter{Schedule}\label{schedule}}

This is a tentative schedule, and it will change. \textbf{BUT} I will do my very best to review this often so that we all stay on the same page and so that you may plan accordingly!

\hypertarget{spring-2023}{%
\section*{Spring 2023}\label{spring-2023}}
\addcontentsline{toc}{section}{Spring 2023}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3636}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3182}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3182}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Date
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Topic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Due
\end{minipage} \\
\midrule()
\endhead
Monday, January 9, 2023 & Course Intro, R4DS, A1 review; Lab 1 & \\
Wednesday, January 11, 2023 & Rmarkdown; ioslides & \\
Friday, January 13, 2023 & Lab 2: Rmarkdown & \textbf{Lab 1 Due} \\
Monday, January 16, 2023 & MLK Holiday & \\
Wednesday, January 18, 2023 & ggplot & \\
Friday, January 20, 2023 & Lab 2: ggplot & \\
Monday, January 23, 2023 & EDA \& ggplot; & \textbf{Lab 2 Due} \\
Wednesday, January 25, 2023 & EDA \& ggplot & \\
Friday, January 27, 2023 & Lab 2: EDA \& ggplot & \\
Monday, January 30, 2023 & Dates and Times & \textbf{Lab 3 Due} \\
Wednesday, February 1, 2023 & Dates and Times & \\
Friday, February 3, 2023 & Relational Data & \\
Monday, February 6, 2023 & Review & \textbf{Lab 4 Due} \\
Wednesday, February 8, 2023 & ** Exam 1** & \\
Friday, February 10, 2023 & Day of Celebtation & \\
Monday, February 13, 2023 & Tidy data from R4DS; Lab 5 & \\
Wednesday, February 15, 2023 & SEDSI & \\
Friday, February 17, 2023 & SEDSI & \\
Monday, February 20, 2023 & Functions; Lab 6 & \textbf{Lab 5 Due} \\
Wednesday, February 22, 2023 & Functions & \\
Friday, February 24, 2023 & Iteration & \\
Monday, February 27, 2023 & Regression & \textbf{Lab 6 Due} \\
Wednesday, March 1, 2023 & Regression (Stepwise) & \\
Friday, March 3, 2023 & ** Exam 2** & ** Exam 2** \\
Monday, March 6, 2023 & Logistic regression & \\
Wednesday, March 8, 2023 & Logistic regression & \\
Friday, March 10, 2023 & Quiz & \textbf{QUIZ} \\
Monday, March 13, 2023 & SPRING BREAK & \\
Wednesday, March 15, 2023 & SPRING BREAK & \\
Friday, March 17, 2023 & SPRING BREAK & \textbf{QUIZ} \\
Monday, March 20, 2023 & Tree-based methods & \\
Wednesday, March 22, 2023 & Tree-based methods & \\
Friday, March 24, 2023 & & \textbf{QUIZ} \\
Monday, March 27, 2023 & Clusters & \\
Wednesday, March 29, 2023 & Clusters & \\
Friday, March 31, 2023 & LAUNCH PROJECT & \textbf{QUIZ} \\
Monday, April 3, 2023 & INDEPENDENT PROJECT & \\
Wednesday, April 5, 2023 & INDEPENDENT PROJECT & \\
Friday, April 7, 2023 & Easter Holidays & \\
Monday, April 10, 2023 & Easter Holidays & \\
Wednesday, April 12, 2023 & INDEPENDENT PROJECT & \\
Friday, April 14, 2023 & INDEPENDENT PROJECT & \\
Monday, April 17, 2023 & INDEPENDENT PROJECT & \\
Wednesday, April 19, 2023 & INDEPENDENT PROJECT & \\
Friday, April 21, 2023 & INDEPENDENT PROJECT & \\
Monday, April 24, 2023 & PRESENTATIONS & \\
Wednesday, April 26, 2023 & PRESENTATIONS & \\
Friday, April 28, 2023 & \textbf{LAST DAY OF CLASSES} & \\
\bottomrule()
\end{longtable}

\hypertarget{lab-1-excercises}{%
\chapter{Lab 1 Excercises}\label{lab-1-excercises}}

Let's make sure we feel good about BADM 371 material.

All open notes/internet/R4DS/etc., \textbf{but all work must be your own}.

Use the starwars data (dplyr package) to answer/do:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Who is the tallest individual? Shortest?
\item
  How many homeworlds are there?
\item
  Which homeworld has the most individuals? Fewest? Average \# of idividuals per homeworld?
\item
  Make a plot of all individuals with mass on the x axis and height on the y axis.
\item
  Put a best fit line on this plot.
\item
  Who is the biggest outlier in this dataset?
\item
  Calculate BMI for all these individuals. What is the average BMI for all individuals?
\item
  What is the average BMI for each homeworld?
\item
  Which homeworlds have the greatest percentage of individuals with BMI's greater than the average you found in \#8 above?
\item
  How many individuals have no missing data? Which variables have the most missing data?
\end{enumerate}

\hypertarget{lab-2-in-rmarkdown}{%
\chapter{Lab 2 in Rmarkdown}\label{lab-2-in-rmarkdown}}

\hypertarget{r-markdown}{%
\section{R Markdown}\label{r-markdown}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Who is the tallest individual? Shortest?
\end{enumerate}

\begin{verbatim}
#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
#>    66.0   167.0   180.0   174.4   191.0   264.0       6
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  How many homeworlds are there?
\end{enumerate}

\begin{verbatim}
#> # A tibble: 49 x 1
#>    homeworld 
#>    <chr>     
#>  1 Tatooine  
#>  2 Naboo     
#>  3 Alderaan  
#>  4 Stewjon   
#>  5 Eriadu    
#>  6 Kashyyyk  
#>  7 Corellia  
#>  8 Rodia     
#>  9 Nal Hutta 
#> 10 Bestine IV
#> # ... with 39 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Which homeworld has the most individuals? Fewest? Average \# of individuals per homeworld?
\end{enumerate}

\begin{verbatim}
#> # A tibble: 49 x 2
#>    homeworld     n
#>    <chr>     <int>
#>  1 Naboo        11
#>  2 Tatooine     10
#>  3 <NA>         10
#>  4 Alderaan      3
#>  5 Coruscant     3
#>  6 Kamino        3
#>  7 Corellia      2
#>  8 Kashyyyk      2
#>  9 Mirial        2
#> 10 Ryloth        2
#> # ... with 39 more rows
#> # A tibble: 49 x 2
#>    homeworld          n
#>    <chr>          <int>
#>  1 Aleen Minor        1
#>  2 Bespin             1
#>  3 Bestine IV         1
#>  4 Cato Neimoidia     1
#>  5 Cerea              1
#>  6 Champala           1
#>  7 Chandrila          1
#>  8 Concord Dawn       1
#>  9 Dathomir           1
#> 10 Dorin              1
#> # ... with 39 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Make a plot of all individuals with mass on the x axis and height on the y axis. Put a best fit line on this plot. Who is the biggest outlier in this dataset?
\end{enumerate}

\includegraphics{101-a1_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{verbatim}
#> # A tibble: 1 x 3
#>   name                   mass height
#>   <chr>                 <dbl>  <int>
#> 1 Jabba Desilijic Tiure  1358    175
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Make something like this:
\end{enumerate}

\hypertarget{why-i-like-this-class}{%
\section{Why I like this class}\label{why-i-like-this-class}}

\hypertarget{its-awesome}{%
\subsection{Its awesome}\label{its-awesome}}

\hypertarget{really-awesome}{%
\subsubsection{Really Awesome}\label{really-awesome}}

\hypertarget{super-duper-awesome}{%
\paragraph{Super Duper Awesome}\label{super-duper-awesome}}

\hypertarget{reason-5}{%
\subparagraph{Reason 5}\label{reason-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  . Make plots like these:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(cars)}
\FunctionTok{plot}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ hp, }\AttributeTok{data =}\NormalTok{ mtcars, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.5\linewidth]{101-a1_files/figure-latex/figures-side-1} \includegraphics[width=0.5\linewidth]{101-a1_files/figure-latex/figures-side-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Calculate BMI for all these individuals. What is the average BMI for all individuals?
\end{enumerate}

\begin{quote}
Via google: With the metric system, the formula for BMI is weight in kilograms divided by height in meters squared. Since height is commonly measured in centimeters, an alternate calculation formula, dividing the weight in kilograms by the height in centimeters squared, and then multiplying the result by 10,000, can be used
\end{quote}

\begin{verbatim}
#> # A tibble: 59 x 4
#>    name                 BMI height  mass
#>    <chr>              <dbl>  <int> <dbl>
#>  1 Luke Skywalker      26.0    172    77
#>  2 C-3PO               26.9    167    75
#>  3 R2-D2               34.7     96    32
#>  4 Darth Vader         33.3    202   136
#>  5 Leia Organa         21.8    150    49
#>  6 Owen Lars           37.9    178   120
#>  7 Beru Whitesun lars  27.5    165    75
#>  8 R5-D4               34.0     97    32
#>  9 Biggs Darklighter   25.1    183    84
#> 10 Obi-Wan Kenobi      23.2    182    77
#> # ... with 49 more rows
#> # A tibble: 1 x 1
#>   `mean(BMI)`
#>         <dbl>
#> 1        32.0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  What is the average BMI for each homeworld?
\end{enumerate}

\begin{verbatim}
#> # A tibble: 40 x 2
#>    homeworld  avg.BMI
#>    <chr>        <dbl>
#>  1 Nal Hutta    443. 
#>  2 Vulpter       50.9
#>  3 Kalee         34.1
#>  4 Bestine IV    34.0
#>  5 <NA>          32.6
#>  6 Malastare     31.9
#>  7 Trandosha     31.3
#>  8 Tatooine      29.3
#>  9 Sullust       26.6
#> 10 Dathomir      26.1
#> # ... with 30 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Which homeworlds have the greatest percentage of individuals with BMI's greater than the average you found in \#8 above?
  How many individuals have no missing data? Which variables have the most missing data?
\end{enumerate}

\begin{verbatim}
#> # A tibble: 5 x 2
#>   homeworld  avg.BMI
#>   <chr>        <dbl>
#> 1 Nal Hutta    443. 
#> 2 Vulpter       50.9
#> 3 Kalee         34.1
#> 4 Bestine IV    34.0
#> 5 <NA>          32.6
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  How many individuals have no missing data?
\end{enumerate}

\begin{quote}
Via google: \url{https://stackoverflow.com/questions/22353633/filter-for-complete-cases-in-data-frame-using-dplyr-case-wise-deletion}
\end{quote}

Single Variable Considered:

\begin{verbatim}
#> # A tibble: 29 x 14
#>    name         height  mass hair_color skin_color eye_color
#>    <chr>         <int> <dbl> <chr>      <chr>      <chr>    
#>  1 Luke Skywal~    172    77 blond      fair       blue     
#>  2 Darth Vader     202   136 none       white      yellow   
#>  3 Leia Organa     150    49 brown      light      brown    
#>  4 Owen Lars       178   120 brown, gr~ light      blue     
#>  5 Beru Whites~    165    75 brown      light      blue     
#>  6 Biggs Darkl~    183    84 black      light      brown    
#>  7 Obi-Wan Ken~    182    77 auburn, w~ fair       blue-gray
#>  8 Anakin Skyw~    188    84 blond      fair       blue     
#>  9 Chewbacca       228   112 brown      unknown    blue     
#> 10 Han Solo        180    80 brown      fair       brown    
#> # ... with 19 more rows, and 8 more variables:
#> #   birth_year <dbl>, sex <chr>, gender <chr>,
#> #   homeworld <chr>, species <chr>, films <list>,
#> #   vehicles <list>, starships <list>
\end{verbatim}

Which variables have the most missing data?

\begin{quote}
Via google: \url{https://stackoverflow.com/questions/26273663/r-how-to-total-the-number-of-na-in-each-col-of-data-frame}
\end{quote}

\hypertarget{all-variables-considered}{%
\chapter{All Variables Considered:}\label{all-variables-considered}}

\begin{verbatim}
#> # A tibble: 1 x 14
#>    name height  mass hair_color skin_color eye_color
#>   <int>  <int> <int>      <int>      <int>     <int>
#> 1     0      6    28          5          0         0
#> # ... with 8 more variables: birth_year <int>, sex <int>,
#> #   gender <int>, homeworld <int>, species <int>,
#> #   films <int>, vehicles <int>, starships <int>
\end{verbatim}

\hypertarget{lab-2-ggplot-without-dsbox}{%
\chapter{\texorpdfstring{Lab 2 -- ggplot without \texttt{dsbox}}{Lab 2 -- ggplot without dsbox}}\label{lab-2-ggplot-without-dsbox}}

\hypertarget{excercises-using-the-data-sets-mpg-or-diamonds}{%
\section{\texorpdfstring{Excercises using the data sets \texttt{mpg} or \texttt{diamonds}}{Excercises using the data sets mpg or diamonds}}\label{excercises-using-the-data-sets-mpg-or-diamonds}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create these figures using the data sets \texttt{mpg} or \texttt{diamonds} as needed:
\end{enumerate}

\includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-1-1.pdf}

\includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-2-1.pdf}

\includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-3-1.pdf}

\hypertarget{palmerpenguins}{%
\section{palmerpenguins}\label{palmerpenguins}}

\texttt{palmerpenguins} is a realtively new package on CRAN, so you can install it from CRAN instead of Github.

Install it like a normal package. After successful installation, you can find out that there are two datasets attached with the package -- penguins and penguins\_raw. You can check out their help page (?penguins\_raw and ?penguins\_raw) to understand more about respective datasets.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Please make a well-labeled, meangingful plot that show how many missing variables there are for each variable in the dataset. Your results shoud look something like this:
\end{enumerate}

\includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Make a plot showing a count of penguins of each species.
\item
  Create a plot that illustrates the relationship between flipper\_length\_mm and body\_mass\_g with respect to each species.
\item
  Create a plot that illustrates the relationship between flipper\_length\_mm and body\_mass\_g with respect to each species for each island.
\item
  Create a few plots of your own using new/interesting geoms and make sure the plots have meangiful, imprmfative labels, too. For possible examples:
\end{enumerate}

\includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-8-1.pdf} \includegraphics{103-ggplot_Lab_no_dsbox_files/figure-latex/unnamed-chunk-8-2.pdf}

\hypertarget{functions}{%
\chapter{Functions}\label{functions}}

\hypertarget{writing-functions}{%
\section{Writing Functions}\label{writing-functions}}

\hypertarget{fahrenheit-to-kelvin}{%
\subsection{Fahrenheit to Kelvin}\label{fahrenheit-to-kelvin}}

\(k = ((f - 32) * (5 / 9)) + 273.15\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{((}\DecValTok{32} \SpecialCharTok{{-}} \DecValTok{32}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{/} \DecValTok{9}\NormalTok{)) }\SpecialCharTok{+} \FloatTok{273.15}
\CommentTok{\#\textgreater{} [1] 273.15}
\NormalTok{((}\DecValTok{212} \SpecialCharTok{{-}} \DecValTok{32}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{/} \DecValTok{9}\NormalTok{)) }\SpecialCharTok{+} \FloatTok{273.15}
\CommentTok{\#\textgreater{} [1] 373.15}
\NormalTok{((}\SpecialCharTok{{-}}\DecValTok{42} \SpecialCharTok{{-}} \DecValTok{32}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{/} \DecValTok{9}\NormalTok{)) }\SpecialCharTok{+} \FloatTok{273.15}
\CommentTok{\#\textgreater{} [1] 232.0389}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_k }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(f\_temp) \{}
\NormalTok{    ((f\_temp }\SpecialCharTok{{-}} \DecValTok{32}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{/} \DecValTok{9}\NormalTok{)) }\SpecialCharTok{+} \FloatTok{273.15}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{f\_k}\NormalTok{(}\DecValTok{32}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 273.15}
\FunctionTok{f\_k}\NormalTok{(}\DecValTok{212}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 373.15}
\FunctionTok{f\_k}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{42}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 232.0389}
\end{Highlighting}
\end{Shaded}

\hypertarget{kelvin-to-celsius}{%
\subsection{Kelvin to Celsius}\label{kelvin-to-celsius}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k\_c }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(temp\_k) \{}
\NormalTok{    temp\_c }\OtherTok{\textless{}{-}}\NormalTok{ temp\_k }\SpecialCharTok{{-}} \FloatTok{273.15}
    \FunctionTok{return}\NormalTok{(temp\_c)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] {-}273.15}
\end{Highlighting}
\end{Shaded}

\hypertarget{fahrenheit-to-celsius}{%
\subsection{Fahrenheit to Celsius}\label{fahrenheit-to-celsius}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_c }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(temp\_f) \{}
\NormalTok{    temp\_k }\OtherTok{\textless{}{-}} \FunctionTok{f\_k}\NormalTok{(temp\_f)}
\NormalTok{    temp\_c }\OtherTok{\textless{}{-}} \FunctionTok{k\_c}\NormalTok{(temp\_k)}
    \FunctionTok{return}\NormalTok{(temp\_c)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{f\_c}\NormalTok{(}\DecValTok{32}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0}
\FunctionTok{f\_c}\NormalTok{(}\DecValTok{212}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 100}
\end{Highlighting}
\end{Shaded}

\hypertarget{testing-functions}{%
\section{Testing Functions}\label{testing-functions}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(testthat)}
\NormalTok{testthat}\SpecialCharTok{::}\FunctionTok{expect\_equal}\NormalTok{(}\FunctionTok{f\_c}\NormalTok{(}\DecValTok{32}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{testthat}\SpecialCharTok{::}\FunctionTok{expect\_equal}\NormalTok{(}\FunctionTok{f\_c}\NormalTok{(}\DecValTok{212}\NormalTok{), }\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise}{%
\section{Exercise}\label{exercise}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What happens if you use \texttt{NA}, \texttt{Inf}, \texttt{-Inf} in your function?
\item
  What are some better names to give the functions we wrote?
\end{enumerate}

\begin{itemize}
\tightlist
\item
  How would you name these functions in a package?
\end{itemize}

\hypertarget{checking-values}{%
\section{Checking values}\label{checking-values}}

Calculating weighted means

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean\_wt }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, w) \{}
  \FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{*}\NormalTok{ w) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean\_wt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 4.333333}
\end{Highlighting}
\end{Shaded}

If you expect the lengths to be the same,
then you should test for it in the function

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean\_wt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 7.666667}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean\_wt }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, w) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(x) }\SpecialCharTok{!=} \FunctionTok{length}\NormalTok{(w)) \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"\textasciigrave{}x\textasciigrave{} and \textasciigrave{}w\textasciigrave{} should be the same length"}\NormalTok{)}
\NormalTok{  \}}
  \FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{*}\NormalTok{ w) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean\_wt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} Error in mean\_wt(1:6, 1:3): \textasciigrave{}x\textasciigrave{} and \textasciigrave{}w\textasciigrave{} should be the same length}
\end{Highlighting}
\end{Shaded}

\hypertarget{dot-dot-dot}{%
\section{dot-dot-dot \ldots{}}\label{dot-dot-dot}}

Use it to pass on arguments to another function inside.

But you can also use it to force named arguments in your function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum\_3 }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, z) \{}
  \FunctionTok{return}\NormalTok{(x }\SpecialCharTok{+}\NormalTok{ y }\SpecialCharTok{+}\NormalTok{ z)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum\_3}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 6}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum\_3 }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, ..., z) \{}
  \FunctionTok{return}\NormalTok{(x }\SpecialCharTok{+}\NormalTok{ y }\SpecialCharTok{+}\NormalTok{ z)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum\_3}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\AttributeTok{z =} \DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 6}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum\_3}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\AttributeTok{z =} \DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 6}
\end{Highlighting}
\end{Shaded}

\hypertarget{conditionals}{%
\section{Conditionals}\label{conditionals}}

\hypertarget{if-statements}{%
\section{if statements}\label{if-statements}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make a modification to this function}
\NormalTok{k\_c }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(temp\_k) \{}
    \ControlFlowTok{if}\NormalTok{ (temp\_k }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
        \FunctionTok{warning}\NormalTok{(}\StringTok{\textquotesingle{}you passed in a negative Kelvin number\textquotesingle{}}\NormalTok{)}
        \CommentTok{\# stop()}
        \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{    temp\_c }\OtherTok{\textless{}{-}}\NormalTok{ temp\_k }\SpecialCharTok{{-}} \FloatTok{273.15}
    \FunctionTok{return}\NormalTok{(temp\_c)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning in k\_c({-}9): you passed in a negative Kelvin number}
\CommentTok{\#\textgreater{} [1] NA}
\end{Highlighting}
\end{Shaded}

Our current function does not deal with missing numbers

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in if (temp_k < 0) { : missing value where TRUE/FALSE needed
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] {-}273.15}
\end{Highlighting}
\end{Shaded}

\hypertarget{if-else-statements}{%
\section{If else statements}\label{if-else-statements}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k\_c }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(temp\_k) \{}
    \ControlFlowTok{if}\NormalTok{ (temp\_k }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
        \FunctionTok{warning}\NormalTok{(}\StringTok{\textquotesingle{}you passed in a negative Kelvin number\textquotesingle{}}\NormalTok{)}
        \CommentTok{\# stop()}
        \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{        temp\_c }\OtherTok{\textless{}{-}}\NormalTok{ temp\_k }\SpecialCharTok{{-}} \FloatTok{273.15}
        \FunctionTok{return}\NormalTok{(temp\_c)}
\NormalTok{    \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning in k\_c({-}9): you passed in a negative Kelvin number}
\CommentTok{\#\textgreater{} [1] NA}
\end{Highlighting}
\end{Shaded}

Our current function does not deal with missing numbers

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] {-}273.15}
\end{Highlighting}
\end{Shaded}

\hypertarget{dealing-with-na}{%
\section{Dealing with NA}\label{dealing-with-na}}

Re-write our function to work with missing values.

Note you need to make the \texttt{NA} check first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k\_c }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(temp\_k) \{}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.na}\NormalTok{(temp\_k)) \{}
        \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (temp\_k }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
        \FunctionTok{warning}\NormalTok{(}\StringTok{\textquotesingle{}you passed in a negative Kelvin number\textquotesingle{}}\NormalTok{)}
        \CommentTok{\# stop()}
        \FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{        temp\_c }\OtherTok{\textless{}{-}}\NormalTok{ temp\_k }\SpecialCharTok{{-}} \FloatTok{273.15}
        \FunctionTok{return}\NormalTok{(temp\_c)}
\NormalTok{    \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning in k\_c({-}9): you passed in a negative Kelvin number}
\CommentTok{\#\textgreater{} [1] NA}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\ConstantTok{NA}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] NA}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{k\_c}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] {-}273.15}
\end{Highlighting}
\end{Shaded}

use \texttt{\&\&} and \texttt{\textbar{}\textbar{}} to short-circuit the boolean comparisons.
This will also guarantee a value of length \texttt{1L}.
\texttt{==} is also vectorized, should use \texttt{identical()} or \texttt{all.equal()}.

\texttt{identical} is very strict. Doesn't corece types.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{identical}\NormalTok{(0L, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] FALSE}
\end{Highlighting}
\end{Shaded}

\texttt{all.equal} has ability to set tolerances.

\texttt{all.equal}: compare R objects x and y testing `near equality'. If they are different, comparison is still made to some extent, and a report of the differences is returned. Do not use all.equal directly in if expressions---either use isTRUE(all.equal(\ldots.)) or identical if appropriate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all.equal}\NormalTok{(0L, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] TRUE}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ (}\FunctionTok{isTRUE}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(0L, }\DecValTok{0}\NormalTok{))) \{}\FunctionTok{print}\NormalTok{(}\StringTok{"Hello"}\NormalTok{)\}}
\CommentTok{\#\textgreater{} [1] "Hello"}
\end{Highlighting}
\end{Shaded}

\hypertarget{fizzbuzz}{%
\section{Fizzbuzz}\label{fizzbuzz}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fizzbuzz }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
  \CommentTok{\# these two lines check that x is a valid input}
  \FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{length}\NormalTok{(x) }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
  \FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{is.numeric}\NormalTok{(x))}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{3}\NormalTok{) }\SpecialCharTok{\&\&} \SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{)) \{}
    \StringTok{"fizzbuzz"}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{3}\NormalTok{)) \{}
    \StringTok{"fizz"}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{)) \{}
    \StringTok{"buzz"}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \CommentTok{\# ensure that the function returns a character vector}
    \FunctionTok{as.character}\NormalTok{(x)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fizzbuzz}\NormalTok{(}\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] "fizz"}
\end{Highlighting}
\end{Shaded}

Check modulo 3 only once

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fizzbuzz2 }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
  \CommentTok{\# these two lines check that x is a valid input}
  \FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{length}\NormalTok{(x) }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
  \FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{is.numeric}\NormalTok{(x))}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{3}\NormalTok{)) \{}
    \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{)) \{}
      \StringTok{"fizzbuzz"}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \StringTok{"fizz"}
\NormalTok{    \}}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{)) \{}
    \StringTok{"buzz"}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \CommentTok{\# ensure that the function returns a character vector}
    \FunctionTok{as.character}\NormalTok{(x)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fizzbuzz}\NormalTok{(}\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] "fizz"}
\end{Highlighting}
\end{Shaded}

\hypertarget{vectorized-conditionals}{%
\subsection{Vectorized conditionals}\label{vectorized-conditionals}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Attaching package: \textquotesingle{}dplyr\textquotesingle{}}
\CommentTok{\#\textgreater{} The following object is masked from \textquotesingle{}package:testthat\textquotesingle{}:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     matches}
\CommentTok{\#\textgreater{} The following objects are masked from \textquotesingle{}package:stats\textquotesingle{}:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     filter, lag}
\CommentTok{\#\textgreater{} The following objects are masked from \textquotesingle{}package:base\textquotesingle{}:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     intersect, setdiff, setequal, union}
\NormalTok{fizzbuzz\_vec }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{case\_when}\NormalTok{(}
    \SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{3}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \StringTok{"fizzbuzz"}\NormalTok{,}
    \SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{3}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \StringTok{"fizz"}\NormalTok{,}
    \SpecialCharTok{!}\NormalTok{(x }\SpecialCharTok{\%\%} \DecValTok{5}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \StringTok{"buzz"}\NormalTok{,}
    \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \FunctionTok{as.character}\NormalTok{(x)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fizzbuzz}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} Error in fizzbuzz(1:10): length(x) == 1 is not TRUE}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fizzbuzz\_vec}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] "1"    "2"    "fizz" "4"    "buzz" "fizz" "7"    "8"   }
\CommentTok{\#\textgreater{}  [9] "fizz" "buzz"}
\end{Highlighting}
\end{Shaded}

\hypertarget{multiple-conditions}{%
\subsection{Multiple conditions}\label{multiple-conditions}}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ (this) \{}
  \CommentTok{\# do that}
\NormalTok{\} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (that) \{}
  \CommentTok{\# do something else}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
  \CommentTok{\# }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{linear-regression}{%
\chapter{Linear Regression}\label{linear-regression}}

Your resource for this is ISLR chapter 3: linear regression.

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make sure you can define the terms below \textbf{outloud}, in your own words, so that they make sense both to you and to someone else (me?). Actually practice saying and defining these terms \textbf{outloud} until your answers make sense:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  least squares approach
\item
  confidence interval
\item
  p-value
\item
  R\textsuperscript{2}
\item
  Adjusted R\textsuperscript{2}
\item
  qualitative predictor
\item
  collinearity
\item
  KNN
\item
  Residual standard error
\item
  F-statistic
\item
  Explain the point of Figure 3.1
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In \texttt{m1}, below, which variables are significant predictors of Balance? How do you know?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"ISLR"}\NormalTok{)}
\FunctionTok{data}\NormalTok{(Credit)}
\FunctionTok{attach}\NormalTok{(Credit)}
\FunctionTok{head}\NormalTok{(Credit)}
\CommentTok{\#\textgreater{}   ID  Income Limit Rating Cards Age Education Gender}
\CommentTok{\#\textgreater{} 1  1  14.891  3606    283     2  34        11   Male}
\CommentTok{\#\textgreater{} 2  2 106.025  6645    483     3  82        15 Female}
\CommentTok{\#\textgreater{} 3  3 104.593  7075    514     4  71        11   Male}
\CommentTok{\#\textgreater{} 4  4 148.924  9504    681     3  36        11 Female}
\CommentTok{\#\textgreater{} 5  5  55.882  4897    357     2  68        16   Male}
\CommentTok{\#\textgreater{} 6  6  80.180  8047    569     4  77        10   Male}
\CommentTok{\#\textgreater{}   Student Married Ethnicity Balance}
\CommentTok{\#\textgreater{} 1      No     Yes Caucasian     333}
\CommentTok{\#\textgreater{} 2     Yes     Yes     Asian     903}
\CommentTok{\#\textgreater{} 3      No      No     Asian     580}
\CommentTok{\#\textgreater{} 4      No      No     Asian     964}
\CommentTok{\#\textgreater{} 5      No     Yes Caucasian     331}
\CommentTok{\#\textgreater{} 6      No      No Caucasian    1151}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Balance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Age }\SpecialCharTok{+}\NormalTok{ Income }\SpecialCharTok{+}\NormalTok{ Education, }\AttributeTok{data =}\NormalTok{ Credit)}
\FunctionTok{summary}\NormalTok{(m1)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = Balance \textasciitilde{} Age + Income + Education, data = Credit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}867.14 {-}343.14  {-}49.44  316.55 1080.56 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) 348.8115   112.6895   3.095  0.00211 ** }
\CommentTok{\#\textgreater{} Age          {-}2.1863     1.2004  {-}1.821  0.06930 .  }
\CommentTok{\#\textgreater{} Income        6.2380     0.5877  10.614  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} Education     0.8058     6.5254   0.123  0.90179    }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 407.2 on 396 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.2215, Adjusted R{-}squared:  0.2156 }
\CommentTok{\#\textgreater{} F{-}statistic: 37.56 on 3 and 396 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  How ``good'' is the model created in \texttt{m1}? How do you know?
\item
  Add more \texttt{Credit} variables to model \texttt{m1}. Can you find two other variables that have extremely high collinearity? What are they? How do you know that they have high collinearity? Why does this make sense given what each of the variables mean?
\item
  Based on the model below, what would you predict the balance to be for an individual who is 40, has an income of \$100,000, 16 years of education, is Asian and not a student?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Balance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Age }\SpecialCharTok{+}\NormalTok{ Income }\SpecialCharTok{+}\NormalTok{ Education }\SpecialCharTok{+}\NormalTok{ Ethnicity }\SpecialCharTok{+}\NormalTok{ Student, }\AttributeTok{data =}\NormalTok{ Credit)}
\FunctionTok{summary}\NormalTok{(m2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = Balance \textasciitilde{} Age + Income + Education + Ethnicity + }
\CommentTok{\#\textgreater{}     Student, data = Credit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}818.77 {-}322.14  {-}54.52  315.67  781.45 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}                    Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept)        336.6241   115.6311   2.911  0.00381 ** }
\CommentTok{\#\textgreater{} Age                 {-}1.9756     1.1595  {-}1.704  0.08922 .  }
\CommentTok{\#\textgreater{} Income               6.1491     0.5666  10.853  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} Education           {-}1.7606     6.3060  {-}0.279  0.78024    }
\CommentTok{\#\textgreater{} EthnicityAsian     {-}14.2547    55.5240  {-}0.257  0.79752    }
\CommentTok{\#\textgreater{} EthnicityCaucasian   8.8839    48.3276   0.184  0.85424    }
\CommentTok{\#\textgreater{} StudentYes         382.0498    65.6854   5.816 1.25e{-}08 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 392.2 on 393 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.2833, Adjusted R{-}squared:  0.2723 }
\CommentTok{\#\textgreater{} F{-}statistic: 25.89 on 6 and 393 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Interpret this model and its output, especially the coefficients \texttt{Income:Education\ \ \ 0.3149}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Balance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Income}\SpecialCharTok{*}\NormalTok{Education, }\AttributeTok{data =}\NormalTok{ Credit)}
\FunctionTok{summary}\NormalTok{(m3)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = Balance \textasciitilde{} Income * Education, data = Credit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}858.07 {-}349.99  {-}56.12  304.51 1083.93 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}                  Estimate Std. Error t value Pr(\textgreater{}|t|)   }
\CommentTok{\#\textgreater{} (Intercept)      435.4599   147.1000   2.960  0.00326 **}
\CommentTok{\#\textgreater{} Income             1.8168     2.4727   0.735  0.46294   }
\CommentTok{\#\textgreater{} Education        {-}13.9887    10.5931  {-}1.321  0.18741   }
\CommentTok{\#\textgreater{} Income:Education   0.3149     0.1788   1.761  0.07902 . }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 407.3 on 396 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.2211, Adjusted R{-}squared:  0.2152 }
\CommentTok{\#\textgreater{} F{-}statistic: 37.47 on 3 and 396 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  What's going on here?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{scipen=}\DecValTok{999}\NormalTok{)}
\FunctionTok{options}\NormalTok{(}\AttributeTok{digits=}\DecValTok{3}\NormalTok{)}
\FunctionTok{library}\NormalTok{(ISLR)}
\FunctionTok{data}\NormalTok{(}\StringTok{"Credit"}\NormalTok{)}
\FunctionTok{attach}\NormalTok{(Credit)}
\CommentTok{\#\textgreater{} The following objects are masked from Credit (pos = 3):}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     Age, Balance, Cards, Education, Ethnicity,}
\CommentTok{\#\textgreater{}     Gender, ID, Income, Limit, Married, Rating,}
\CommentTok{\#\textgreater{}     Student}
\NormalTok{?Credit}
\CommentTok{\#\textgreater{} starting httpd help server ...}
\CommentTok{\#\textgreater{}  done}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Balance}\SpecialCharTok{\textasciitilde{}}\NormalTok{Income}\SpecialCharTok{+}\NormalTok{Education)}
\FunctionTok{summary}\NormalTok{(m1)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = Balance \textasciitilde{} Income + Education)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}    Min     1Q Median     3Q    Max }
\CommentTok{\#\textgreater{} {-}806.2 {-}349.7  {-}53.4  330.4 1103.4 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value            Pr(\textgreater{}|t|)}
\CommentTok{\#\textgreater{} (Intercept)  236.975     94.767    2.50               0.013}
\CommentTok{\#\textgreater{} Income         6.050      0.580   10.43 \textless{}0.0000000000000002}
\CommentTok{\#\textgreater{} Education      0.703      6.544    0.11               0.914}
\CommentTok{\#\textgreater{}                }
\CommentTok{\#\textgreater{} (Intercept) *  }
\CommentTok{\#\textgreater{} Income      ***}
\CommentTok{\#\textgreater{} Education      }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 408 on 397 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.215,  Adjusted R{-}squared:  0.211 }
\CommentTok{\#\textgreater{} F{-}statistic: 54.4 on 2 and 397 DF,  p{-}value: \textless{}0.0000000000000002}
\FloatTok{236.975}\SpecialCharTok{+}\NormalTok{(}\FloatTok{6.050} \SpecialCharTok{*}\DecValTok{100}\NormalTok{)}\SpecialCharTok{+}\NormalTok{(}\FloatTok{0.703}\SpecialCharTok{*}\DecValTok{12}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 850}
\FunctionTok{predict}\NormalTok{(m1, }\AttributeTok{newdata =} \FunctionTok{list}\NormalTok{(}\AttributeTok{Income =} \DecValTok{100}\NormalTok{, }\AttributeTok{Education =} \DecValTok{12}\NormalTok{))}
\CommentTok{\#\textgreater{}   1 }
\CommentTok{\#\textgreater{} 850}

\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Balance}\SpecialCharTok{\textasciitilde{}}\NormalTok{Income}\SpecialCharTok{*}\NormalTok{Education)}
\FunctionTok{summary}\NormalTok{(m2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = Balance \textasciitilde{} Income * Education)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}    Min     1Q Median     3Q    Max }
\CommentTok{\#\textgreater{} {-}858.1 {-}350.0  {-}56.1  304.5 1083.9 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}                  Estimate Std. Error t value Pr(\textgreater{}|t|)   }
\CommentTok{\#\textgreater{} (Intercept)       435.460    147.100    2.96   0.0033 **}
\CommentTok{\#\textgreater{} Income              1.817      2.473    0.73   0.4629   }
\CommentTok{\#\textgreater{} Education         {-}13.989     10.593   {-}1.32   0.1874   }
\CommentTok{\#\textgreater{} Income:Education    0.315      0.179    1.76   0.0790 . }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 407 on 396 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.221,  Adjusted R{-}squared:  0.215 }
\CommentTok{\#\textgreater{} F{-}statistic: 37.5 on 3 and 396 DF,  p{-}value: \textless{}0.0000000000000002}

\FloatTok{435.460}\SpecialCharTok{+}\NormalTok{(}\FloatTok{1.817}\SpecialCharTok{*}\DecValTok{100}\NormalTok{)}\SpecialCharTok{+}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{13.989}\SpecialCharTok{*}\DecValTok{12}\NormalTok{)}\SpecialCharTok{+}\NormalTok{(}\FloatTok{0.315}\SpecialCharTok{*}\DecValTok{100}\SpecialCharTok{*}\DecValTok{12}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 827}
\FunctionTok{predict}\NormalTok{(m2, }\AttributeTok{newdata =} \FunctionTok{list}\NormalTok{(}\AttributeTok{Income =} \DecValTok{100}\NormalTok{, }\AttributeTok{Education =} \DecValTok{12}\NormalTok{))}
\CommentTok{\#\textgreater{}   1 }
\CommentTok{\#\textgreater{} 827}
\end{Highlighting}
\end{Shaded}

\hypertarget{logistic-regression}{%
\chapter{Logistic Regression}\label{logistic-regression}}

Your resource for this is ISLR Chapter 4: Classification.

\hypertarget{tree-based-methods}{%
\chapter{Tree-Based Methods}\label{tree-based-methods}}

Your resource for this is ISLR Chapter 8: Tree-Based Methods.

Make sure you can exlain the terms/ideas/figures below \textbf{outloud}, in your own words, so that they make sense both to you and to someone else (me?). Actually practice exlaining the terms/ideas/figures \textbf{outloud} until your answers make sense:

\begin{itemize}
\tightlist
\item
  Regression vs.~classification trees
\item
  Understand Figure 8.1, Figure 8.2, Algorithm 8.1, Figure 8.3, Figure 8.4, Figure 8.5, Figure 8.6, Figure 8.7
\item
  Be able to explain the +'s and -'s of trees (see section 8.1.4)
\item
  Understand ``combining a large number of trees
  can often result in dramatic improvements in prediction accuracy, at the expense of some loss in interpretation.''
\item
  top-down, greedy approach (aka recursive binary splitting)
\item
  tree pruning and subtrees
\item
  cost complexity pruning (aka weakest link pruning)
\item
  bagging
\item
  random forests
\item
  boosting
\item
  Bayesian additive regression trees
\end{itemize}

\hypertarget{chapter-8-lab-decision-trees}{%
\chapter{Chapter 8 Lab: Decision Trees}\label{chapter-8-lab-decision-trees}}

**Check out this Video: StatsLearning Lect10 R trees A 111213

Or Click Here: \href{https://www.youtube.com/watch?v=YPz2J5lHeVM\&list=PLAOUn-KLSAVOqj5TG8E1HTb8Txwxe6OtV\&index=6}{Here!!!}

\begin{Shaded}
\begin{Highlighting}[]

\DocumentationTok{\#\# Fitting Classification Trees}

\DocumentationTok{\#\#\#}
\FunctionTok{library}\NormalTok{(tree)}
\DocumentationTok{\#\#\#}
\FunctionTok{library}\NormalTok{(ISLR2)}
\FunctionTok{attach}\NormalTok{(Carseats)}
\NormalTok{High }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(Sales }\SpecialCharTok{\textless{}=} \DecValTok{8}\NormalTok{, }\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{))}
\DocumentationTok{\#\#\#}
\NormalTok{Carseats }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(Carseats, High)}
\DocumentationTok{\#\#\#}
\NormalTok{tree.carseats }\OtherTok{\textless{}{-}} \FunctionTok{tree}\NormalTok{(High }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\NormalTok{ Sales, Carseats)}
\DocumentationTok{\#\#\#}
\FunctionTok{summary}\NormalTok{(tree.carseats)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Classification tree:}
\CommentTok{\#\textgreater{} tree(formula = High \textasciitilde{} . {-} Sales, data = Carseats)}
\CommentTok{\#\textgreater{} Variables actually used in tree construction:}
\CommentTok{\#\textgreater{} [1] "ShelveLoc"   "Price"       "Income"      "CompPrice"  }
\CommentTok{\#\textgreater{} [5] "Population"  "Advertising" "Age"         "US"         }
\CommentTok{\#\textgreater{} Number of terminal nodes:  27 }
\CommentTok{\#\textgreater{} Residual mean deviance:  0.4575 = 170.7 / 373 }
\CommentTok{\#\textgreater{} Misclassification error rate: 0.09 = 36 / 400}
\DocumentationTok{\#\#\#}
\FunctionTok{plot}\NormalTok{(tree.carseats)}
\FunctionTok{text}\NormalTok{(tree.carseats, }\AttributeTok{pretty =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#}
\NormalTok{tree.carseats}
\CommentTok{\#\textgreater{} node), split, n, deviance, yval, (yprob)}
\CommentTok{\#\textgreater{}       * denotes terminal node}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   1) root 400 541.500 No ( 0.59000 0.41000 )  }
\CommentTok{\#\textgreater{}     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  }
\CommentTok{\#\textgreater{}       4) Price \textless{} 92.5 46  56.530 Yes ( 0.30435 0.69565 )  }
\CommentTok{\#\textgreater{}         8) Income \textless{} 57 10  12.220 No ( 0.70000 0.30000 )  }
\CommentTok{\#\textgreater{}          16) CompPrice \textless{} 110.5 5   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}          17) CompPrice \textgreater{} 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *}
\CommentTok{\#\textgreater{}         9) Income \textgreater{} 57 36  35.470 Yes ( 0.19444 0.80556 )  }
\CommentTok{\#\textgreater{}          18) Population \textless{} 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *}
\CommentTok{\#\textgreater{}          19) Population \textgreater{} 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *}
\CommentTok{\#\textgreater{}       5) Price \textgreater{} 92.5 269 299.800 No ( 0.75465 0.24535 )  }
\CommentTok{\#\textgreater{}        10) Advertising \textless{} 13.5 224 213.200 No ( 0.81696 0.18304 )  }
\CommentTok{\#\textgreater{}          20) CompPrice \textless{} 124.5 96  44.890 No ( 0.93750 0.06250 )  }
\CommentTok{\#\textgreater{}            40) Price \textless{} 106.5 38  33.150 No ( 0.84211 0.15789 )  }
\CommentTok{\#\textgreater{}              80) Population \textless{} 177 12  16.300 No ( 0.58333 0.41667 )  }
\CommentTok{\#\textgreater{}               160) Income \textless{} 60.5 6   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}               161) Income \textgreater{} 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *}
\CommentTok{\#\textgreater{}              81) Population \textgreater{} 177 26   8.477 No ( 0.96154 0.03846 ) *}
\CommentTok{\#\textgreater{}            41) Price \textgreater{} 106.5 58   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}          21) CompPrice \textgreater{} 124.5 128 150.200 No ( 0.72656 0.27344 )  }
\CommentTok{\#\textgreater{}            42) Price \textless{} 122.5 51  70.680 Yes ( 0.49020 0.50980 )  }
\CommentTok{\#\textgreater{}              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *}
\CommentTok{\#\textgreater{}              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  }
\CommentTok{\#\textgreater{}               170) Price \textless{} 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *}
\CommentTok{\#\textgreater{}               171) Price \textgreater{} 109.5 24  32.600 No ( 0.58333 0.41667 )  }
\CommentTok{\#\textgreater{}                 342) Age \textless{} 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *}
\CommentTok{\#\textgreater{}                 343) Age \textgreater{} 49.5 11   6.702 No ( 0.90909 0.09091 ) *}
\CommentTok{\#\textgreater{}            43) Price \textgreater{} 122.5 77  55.540 No ( 0.88312 0.11688 )  }
\CommentTok{\#\textgreater{}              86) CompPrice \textless{} 147.5 58  17.400 No ( 0.96552 0.03448 ) *}
\CommentTok{\#\textgreater{}              87) CompPrice \textgreater{} 147.5 19  25.010 No ( 0.63158 0.36842 )  }
\CommentTok{\#\textgreater{}               174) Price \textless{} 147 12  16.300 Yes ( 0.41667 0.58333 )  }
\CommentTok{\#\textgreater{}                 348) CompPrice \textless{} 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *}
\CommentTok{\#\textgreater{}                 349) CompPrice \textgreater{} 152.5 5   5.004 No ( 0.80000 0.20000 ) *}
\CommentTok{\#\textgreater{}               175) Price \textgreater{} 147 7   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}        11) Advertising \textgreater{} 13.5 45  61.830 Yes ( 0.44444 0.55556 )  }
\CommentTok{\#\textgreater{}          22) Age \textless{} 54.5 25  25.020 Yes ( 0.20000 0.80000 )  }
\CommentTok{\#\textgreater{}            44) CompPrice \textless{} 130.5 14  18.250 Yes ( 0.35714 0.64286 )  }
\CommentTok{\#\textgreater{}              88) Income \textless{} 100 9  12.370 No ( 0.55556 0.44444 ) *}
\CommentTok{\#\textgreater{}              89) Income \textgreater{} 100 5   0.000 Yes ( 0.00000 1.00000 ) *}
\CommentTok{\#\textgreater{}            45) CompPrice \textgreater{} 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *}
\CommentTok{\#\textgreater{}          23) Age \textgreater{} 54.5 20  22.490 No ( 0.75000 0.25000 )  }
\CommentTok{\#\textgreater{}            46) CompPrice \textless{} 122.5 10   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}            47) CompPrice \textgreater{} 122.5 10  13.860 No ( 0.50000 0.50000 )  }
\CommentTok{\#\textgreater{}              94) Price \textless{} 125 5   0.000 Yes ( 0.00000 1.00000 ) *}
\CommentTok{\#\textgreater{}              95) Price \textgreater{} 125 5   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  }
\CommentTok{\#\textgreater{}       6) Price \textless{} 135 68  49.260 Yes ( 0.11765 0.88235 )  }
\CommentTok{\#\textgreater{}        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  }
\CommentTok{\#\textgreater{}          24) Price \textless{} 109 8   0.000 Yes ( 0.00000 1.00000 ) *}
\CommentTok{\#\textgreater{}          25) Price \textgreater{} 109 9  11.460 No ( 0.66667 0.33333 ) *}
\CommentTok{\#\textgreater{}        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *}
\CommentTok{\#\textgreater{}       7) Price \textgreater{} 135 17  22.070 No ( 0.64706 0.35294 )  }
\CommentTok{\#\textgreater{}        14) Income \textless{} 46 6   0.000 No ( 1.00000 0.00000 ) *}
\CommentTok{\#\textgreater{}        15) Income \textgreater{} 46 11  15.160 Yes ( 0.45455 0.54545 ) *}
\DocumentationTok{\#\#\#}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{train }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(Carseats), }\DecValTok{200}\NormalTok{)}
\NormalTok{Carseats.test }\OtherTok{\textless{}{-}}\NormalTok{ Carseats[}\SpecialCharTok{{-}}\NormalTok{train, ]}
\NormalTok{High.test }\OtherTok{\textless{}{-}}\NormalTok{ High[}\SpecialCharTok{{-}}\NormalTok{train]}
\NormalTok{tree.carseats }\OtherTok{\textless{}{-}} \FunctionTok{tree}\NormalTok{(High }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\NormalTok{ Sales, Carseats,}
                      \AttributeTok{subset =}\NormalTok{ train)}
\NormalTok{tree.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree.carseats, Carseats.test,}
                     \AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(tree.pred, High.test)}
\CommentTok{\#\textgreater{}          High.test}
\CommentTok{\#\textgreater{} tree.pred  No Yes}
\CommentTok{\#\textgreater{}       No  104  33}
\CommentTok{\#\textgreater{}       Yes  13  50}
\NormalTok{(}\DecValTok{104} \SpecialCharTok{+} \DecValTok{50}\NormalTok{) }\SpecialCharTok{/} \DecValTok{200}
\CommentTok{\#\textgreater{} [1] 0.77}
\DocumentationTok{\#\#\#}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{7}\NormalTok{)}
\NormalTok{cv.carseats }\OtherTok{\textless{}{-}} \FunctionTok{cv.tree}\NormalTok{(tree.carseats, }\AttributeTok{FUN =}\NormalTok{ prune.misclass)}
\FunctionTok{names}\NormalTok{(cv.carseats)}
\CommentTok{\#\textgreater{} [1] "size"   "dev"    "k"      "method"}
\NormalTok{cv.carseats}
\CommentTok{\#\textgreater{} $size}
\CommentTok{\#\textgreater{} [1] 21 19 14  9  8  5  3  2  1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $dev}
\CommentTok{\#\textgreater{} [1] 75 75 75 74 82 83 83 85 82}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $k}
\CommentTok{\#\textgreater{} [1] {-}Inf  0.0  1.0  1.4  2.0  3.0  4.0  9.0 18.0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $method}
\CommentTok{\#\textgreater{} [1] "misclass"}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} attr(,"class")}
\CommentTok{\#\textgreater{} [1] "prune"         "tree.sequence"}
\DocumentationTok{\#\#\#}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(cv.carseats}\SpecialCharTok{$}\NormalTok{size, cv.carseats}\SpecialCharTok{$}\NormalTok{dev, }\AttributeTok{type =} \StringTok{"b"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(cv.carseats}\SpecialCharTok{$}\NormalTok{k, cv.carseats}\SpecialCharTok{$}\NormalTok{dev, }\AttributeTok{type =} \StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#}
\NormalTok{prune.carseats }\OtherTok{\textless{}{-}} \FunctionTok{prune.misclass}\NormalTok{(tree.carseats, }\AttributeTok{best =} \DecValTok{9}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(prune.carseats)}
\FunctionTok{text}\NormalTok{(prune.carseats, }\AttributeTok{pretty =} \DecValTok{0}\NormalTok{)}
\DocumentationTok{\#\#\#}
\NormalTok{tree.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(prune.carseats, Carseats.test,}
                     \AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(tree.pred, High.test)}
\CommentTok{\#\textgreater{}          High.test}
\CommentTok{\#\textgreater{} tree.pred No Yes}
\CommentTok{\#\textgreater{}       No  97  25}
\CommentTok{\#\textgreater{}       Yes 20  58}
\NormalTok{(}\DecValTok{97} \SpecialCharTok{+} \DecValTok{58}\NormalTok{) }\SpecialCharTok{/} \DecValTok{200}
\CommentTok{\#\textgreater{} [1] 0.775}
\DocumentationTok{\#\#\#}
\NormalTok{prune.carseats }\OtherTok{\textless{}{-}} \FunctionTok{prune.misclass}\NormalTok{(tree.carseats, }\AttributeTok{best =} \DecValTok{14}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(prune.carseats)}
\FunctionTok{text}\NormalTok{(prune.carseats, }\AttributeTok{pretty =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(prune.carseats, Carseats.test,}
                     \AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(tree.pred, High.test)}
\CommentTok{\#\textgreater{}          High.test}
\CommentTok{\#\textgreater{} tree.pred  No Yes}
\CommentTok{\#\textgreater{}       No  102  31}
\CommentTok{\#\textgreater{}       Yes  15  52}
\NormalTok{(}\DecValTok{102} \SpecialCharTok{+} \DecValTok{52}\NormalTok{) }\SpecialCharTok{/} \DecValTok{200}
\CommentTok{\#\textgreater{} [1] 0.77}

\DocumentationTok{\#\# Fitting Regression Trees}

\DocumentationTok{\#\#\#}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{train }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(Boston), }\FunctionTok{nrow}\NormalTok{(Boston) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{tree.boston }\OtherTok{\textless{}{-}} \FunctionTok{tree}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., Boston, }\AttributeTok{subset =}\NormalTok{ train)}
\FunctionTok{summary}\NormalTok{(tree.boston)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Regression tree:}
\CommentTok{\#\textgreater{} tree(formula = medv \textasciitilde{} ., data = Boston, subset = train)}
\CommentTok{\#\textgreater{} Variables actually used in tree construction:}
\CommentTok{\#\textgreater{} [1] "rm"    "lstat" "crim"  "age"  }
\CommentTok{\#\textgreater{} Number of terminal nodes:  7 }
\CommentTok{\#\textgreater{} Residual mean deviance:  10.38 = 2555 / 246 }
\CommentTok{\#\textgreater{} Distribution of residuals:}
\CommentTok{\#\textgreater{}     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. }
\CommentTok{\#\textgreater{} {-}10.1800  {-}1.7770  {-}0.1775   0.0000   1.9230  16.5800}
\DocumentationTok{\#\#\#}
\FunctionTok{plot}\NormalTok{(tree.boston)}
\FunctionTok{text}\NormalTok{(tree.boston, }\AttributeTok{pretty =} \DecValTok{0}\NormalTok{)}
\DocumentationTok{\#\#\#}
\NormalTok{cv.boston }\OtherTok{\textless{}{-}} \FunctionTok{cv.tree}\NormalTok{(tree.boston)}
\FunctionTok{plot}\NormalTok{(cv.boston}\SpecialCharTok{$}\NormalTok{size, cv.boston}\SpecialCharTok{$}\NormalTok{dev, }\AttributeTok{type =} \StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#}
\NormalTok{prune.boston }\OtherTok{\textless{}{-}} \FunctionTok{prune.tree}\NormalTok{(tree.boston, }\AttributeTok{best =} \DecValTok{5}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(prune.boston)}
\FunctionTok{text}\NormalTok{(prune.boston, }\AttributeTok{pretty =} \DecValTok{0}\NormalTok{)}
\DocumentationTok{\#\#\#}
\NormalTok{yhat }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree.boston, }\AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ])}
\NormalTok{boston.test }\OtherTok{\textless{}{-}}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, }\StringTok{"medv"}\NormalTok{]}
\FunctionTok{plot}\NormalTok{(yhat, boston.test)}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-5.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{((yhat }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 35.28688}

\DocumentationTok{\#\# Bagging and Random Forests}

\DocumentationTok{\#\#\#}
\FunctionTok{library}\NormalTok{(randomForest)}
\CommentTok{\#\textgreater{} randomForest 4.7{-}1}
\CommentTok{\#\textgreater{} Type rfNews() to see new features/changes/bug fixes.}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{bag.boston }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ Boston,}
                           \AttributeTok{subset =}\NormalTok{ train, }\AttributeTok{mtry =} \DecValTok{12}\NormalTok{, }\AttributeTok{importance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{bag.boston}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{}  randomForest(formula = medv \textasciitilde{} ., data = Boston, mtry = 12, importance = TRUE,      subset = train) }
\CommentTok{\#\textgreater{}                Type of random forest: regression}
\CommentTok{\#\textgreater{}                      Number of trees: 500}
\CommentTok{\#\textgreater{} No. of variables tried at each split: 12}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}           Mean of squared residuals: 11.40162}
\CommentTok{\#\textgreater{}                     \% Var explained: 85.17}
\DocumentationTok{\#\#\#}
\NormalTok{yhat.bag }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(bag.boston, }\AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ])}
\FunctionTok{plot}\NormalTok{(yhat.bag, boston.test)}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\FunctionTok{mean}\NormalTok{((yhat.bag }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 23.41916}
\DocumentationTok{\#\#\#}
\NormalTok{bag.boston }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ Boston,}
                           \AttributeTok{subset =}\NormalTok{ train, }\AttributeTok{mtry =} \DecValTok{12}\NormalTok{, }\AttributeTok{ntree =} \DecValTok{25}\NormalTok{)}
\NormalTok{yhat.bag }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(bag.boston, }\AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ])}
\FunctionTok{mean}\NormalTok{((yhat.bag }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 25.75055}
\DocumentationTok{\#\#\#}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{rf.boston }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ Boston,}
                          \AttributeTok{subset =}\NormalTok{ train, }\AttributeTok{mtry =} \DecValTok{6}\NormalTok{, }\AttributeTok{importance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{yhat.rf }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(rf.boston, }\AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ])}
\FunctionTok{mean}\NormalTok{((yhat.rf }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 20.06644}
\DocumentationTok{\#\#\#}
\FunctionTok{importance}\NormalTok{(rf.boston)}
\CommentTok{\#\textgreater{}           \%IncMSE IncNodePurity}
\CommentTok{\#\textgreater{} crim    19.435587    1070.42307}
\CommentTok{\#\textgreater{} zn       3.091630      82.19257}
\CommentTok{\#\textgreater{} indus    6.140529     590.09536}
\CommentTok{\#\textgreater{} chas     1.370310      36.70356}
\CommentTok{\#\textgreater{} nox     13.263466     859.97091}
\CommentTok{\#\textgreater{} rm      35.094741    8270.33906}
\CommentTok{\#\textgreater{} age     15.144821     634.31220}
\CommentTok{\#\textgreater{} dis      9.163776     684.87953}
\CommentTok{\#\textgreater{} rad      4.793720      83.18719}
\CommentTok{\#\textgreater{} tax      4.410714     292.20949}
\CommentTok{\#\textgreater{} ptratio  8.612780     902.20190}
\CommentTok{\#\textgreater{} lstat   28.725343    5813.04833}
\DocumentationTok{\#\#\#}
\FunctionTok{varImpPlot}\NormalTok{(rf.boston)}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-6.pdf}

\begin{Shaded}
\begin{Highlighting}[]

\DocumentationTok{\#\# Boosting}

\DocumentationTok{\#\#\#}
\FunctionTok{library}\NormalTok{(gbm)}
\CommentTok{\#\textgreater{} Loaded gbm 2.1.8}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-7.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{boost.boston }\OtherTok{\textless{}{-}} \FunctionTok{gbm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ Boston[train, ],}
                    \AttributeTok{distribution =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{n.trees =} \DecValTok{5000}\NormalTok{,}
                    \AttributeTok{interaction.depth =} \DecValTok{4}\NormalTok{)}
\DocumentationTok{\#\#\#}
\FunctionTok{summary}\NormalTok{(boost.boston)}
\CommentTok{\#\textgreater{}             var     rel.inf}
\CommentTok{\#\textgreater{} rm           rm 44.48249588}
\CommentTok{\#\textgreater{} lstat     lstat 32.70281223}
\CommentTok{\#\textgreater{} crim       crim  4.85109954}
\CommentTok{\#\textgreater{} dis         dis  4.48693083}
\CommentTok{\#\textgreater{} nox         nox  3.75222394}
\CommentTok{\#\textgreater{} age         age  3.19769210}
\CommentTok{\#\textgreater{} ptratio ptratio  2.81354826}
\CommentTok{\#\textgreater{} tax         tax  1.54417603}
\CommentTok{\#\textgreater{} indus     indus  1.03384666}
\CommentTok{\#\textgreater{} rad         rad  0.87625748}
\CommentTok{\#\textgreater{} zn           zn  0.16220479}
\CommentTok{\#\textgreater{} chas       chas  0.09671228}
\DocumentationTok{\#\#\#}
\FunctionTok{plot}\NormalTok{(boost.boston, }\AttributeTok{i =} \StringTok{"rm"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(boost.boston, }\AttributeTok{i =} \StringTok{"lstat"}\NormalTok{)}
\DocumentationTok{\#\#\#}
\NormalTok{yhat.boost }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(boost.boston,}
                      \AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ], }\AttributeTok{n.trees =} \DecValTok{5000}\NormalTok{)}
\FunctionTok{mean}\NormalTok{((yhat.boost }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 18.39057}
\DocumentationTok{\#\#\#}
\NormalTok{boost.boston }\OtherTok{\textless{}{-}} \FunctionTok{gbm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ Boston[train, ],}
                    \AttributeTok{distribution =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{n.trees =} \DecValTok{5000}\NormalTok{,}
                    \AttributeTok{interaction.depth =} \DecValTok{4}\NormalTok{, }\AttributeTok{shrinkage =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{verbose =}\NormalTok{ F)}
\NormalTok{yhat.boost }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(boost.boston,}
                      \AttributeTok{newdata =}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{train, ], }\AttributeTok{n.trees =} \DecValTok{5000}\NormalTok{)}
\FunctionTok{mean}\NormalTok{((yhat.boost }\SpecialCharTok{{-}}\NormalTok{ boston.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 16.54778}

\DocumentationTok{\#\# Bayesian Additive Regression Trees}

\DocumentationTok{\#\#\#}
\FunctionTok{library}\NormalTok{(BART)}
\CommentTok{\#\textgreater{} Loading required package: nlme}
\CommentTok{\#\textgreater{} Loading required package: nnet}
\CommentTok{\#\textgreater{} Loading required package: survival}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ Boston[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{12}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ Boston[, }\StringTok{"medv"}\NormalTok{]}
\NormalTok{xtrain }\OtherTok{\textless{}{-}}\NormalTok{ x[train, ]}
\NormalTok{ytrain }\OtherTok{\textless{}{-}}\NormalTok{ y[train]}
\NormalTok{xtest }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{{-}}\NormalTok{train, ]}
\NormalTok{ytest }\OtherTok{\textless{}{-}}\NormalTok{ y[}\SpecialCharTok{{-}}\NormalTok{train]}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{bartfit }\OtherTok{\textless{}{-}} \FunctionTok{gbart}\NormalTok{(xtrain, ytrain, }\AttributeTok{x.test =}\NormalTok{ xtest)}
\CommentTok{\#\textgreater{} *****Calling gbart: type=1}
\CommentTok{\#\textgreater{} *****Data:}
\CommentTok{\#\textgreater{} data:n,p,np: 253, 12, 253}
\CommentTok{\#\textgreater{} y1,yn: 0.213439, {-}5.486561}
\CommentTok{\#\textgreater{} x1,x[n*p]: 0.109590, 20.080000}
\CommentTok{\#\textgreater{} xp1,xp[np*p]: 0.027310, 7.880000}
\CommentTok{\#\textgreater{} *****Number of Trees: 200}
\CommentTok{\#\textgreater{} *****Number of Cut Points: 100 ... 100}
\CommentTok{\#\textgreater{} *****burn,nd,thin: 100,1000,1}
\CommentTok{\#\textgreater{} *****Prior:beta,alpha,tau,nu,lambda,offset: 2,0.95,0.795495,3,3.71636,21.7866}
\CommentTok{\#\textgreater{} *****sigma: 4.367914}
\CommentTok{\#\textgreater{} *****w (weights): 1.000000 ... 1.000000}
\CommentTok{\#\textgreater{} *****Dirichlet:sparse,theta,omega,a,b,rho,augment: 0,0,1,0.5,1,12,0}
\CommentTok{\#\textgreater{} *****printevery: 100}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} MCMC}
\CommentTok{\#\textgreater{} done 0 (out of 1100)}
\CommentTok{\#\textgreater{} done 100 (out of 1100)}
\CommentTok{\#\textgreater{} done 200 (out of 1100)}
\CommentTok{\#\textgreater{} done 300 (out of 1100)}
\CommentTok{\#\textgreater{} done 400 (out of 1100)}
\CommentTok{\#\textgreater{} done 500 (out of 1100)}
\CommentTok{\#\textgreater{} done 600 (out of 1100)}
\CommentTok{\#\textgreater{} done 700 (out of 1100)}
\CommentTok{\#\textgreater{} done 800 (out of 1100)}
\CommentTok{\#\textgreater{} done 900 (out of 1100)}
\CommentTok{\#\textgreater{} done 1000 (out of 1100)}
\CommentTok{\#\textgreater{} time: 4s}
\CommentTok{\#\textgreater{} trcnt,tecnt: 1000,1000}
\DocumentationTok{\#\#\#}
\NormalTok{yhat.bart }\OtherTok{\textless{}{-}}\NormalTok{ bartfit}\SpecialCharTok{$}\NormalTok{yhat.test.mean}
\FunctionTok{mean}\NormalTok{((ytest }\SpecialCharTok{{-}}\NormalTok{ yhat.bart)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 15.94718}
\DocumentationTok{\#\#\#}
\NormalTok{ord }\OtherTok{\textless{}{-}} \FunctionTok{order}\NormalTok{(bartfit}\SpecialCharTok{$}\NormalTok{varcount.mean, }\AttributeTok{decreasing =}\NormalTok{ T)}
\NormalTok{bartfit}\SpecialCharTok{$}\NormalTok{varcount.mean[ord]}
\CommentTok{\#\textgreater{}     nox   lstat     tax     rad      rm   indus    chas }
\CommentTok{\#\textgreater{}  22.952  21.329  21.250  20.781  19.890  19.825  19.051 }
\CommentTok{\#\textgreater{} ptratio     age      zn     dis    crim }
\CommentTok{\#\textgreater{}  18.976  18.274  15.952  14.457  11.007}
\DocumentationTok{\#\#\#}
\end{Highlighting}
\end{Shaded}

\includegraphics{119-ch_8_lab_files/figure-latex/unnamed-chunk-1-8.pdf}

\hypertarget{trees-9-the-oj-dataset}{%
\chapter{Trees \#9 The OJ Dataset}\label{trees-9-the-oj-dataset}}

This problem involves the OJ data set which is part of the ISLR package.

\begin{verbatim}
#> 
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#> 
#>     filter, lag
#> The following objects are masked from 'package:base':
#> 
#>     intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(OJ)}
\CommentTok{\#\textgreater{} Rows: 1,070}
\CommentTok{\#\textgreater{} Columns: 18}
\CommentTok{\#\textgreater{} $ Purchase       \textless{}fct\textgreater{} CH, CH, CH, MM, CH, CH, CH, CH, CH,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ WeekofPurchase \textless{}dbl\textgreater{} 237, 239, 245, 227, 228, 230, 232, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ StoreID        \textless{}dbl\textgreater{} 1, 1, 1, 1, 7, 7, 7, 7, 7, 7, 7, 7,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ PriceCH        \textless{}dbl\textgreater{} 1.75, 1.75, 1.86, 1.69, 1.69, 1.69,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ PriceMM        \textless{}dbl\textgreater{} 1.99, 1.99, 2.09, 1.69, 1.69, 1.99,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ DiscCH         \textless{}dbl\textgreater{} 0.00, 0.00, 0.17, 0.00, 0.00, 0.00,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ DiscMM         \textless{}dbl\textgreater{} 0.00, 0.30, 0.00, 0.00, 0.00, 0.00,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ SpecialCH      \textless{}dbl\textgreater{} 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ SpecialMM      \textless{}dbl\textgreater{} 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ LoyalCH        \textless{}dbl\textgreater{} 0.500000, 0.600000, 0.680000, 0.400\textasciitilde{}}
\CommentTok{\#\textgreater{} $ SalePriceMM    \textless{}dbl\textgreater{} 1.99, 1.69, 2.09, 1.69, 1.69, 1.99,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ SalePriceCH    \textless{}dbl\textgreater{} 1.75, 1.75, 1.69, 1.69, 1.69, 1.69,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ PriceDiff      \textless{}dbl\textgreater{} 0.24, {-}0.06, 0.40, 0.00, 0.00, 0.30\textasciitilde{}}
\CommentTok{\#\textgreater{} $ Store7         \textless{}fct\textgreater{} No, No, No, No, Yes, Yes, Yes, Yes,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ PctDiscMM      \textless{}dbl\textgreater{} 0.000000, 0.150754, 0.000000, 0.000\textasciitilde{}}
\CommentTok{\#\textgreater{} $ PctDiscCH      \textless{}dbl\textgreater{} 0.000000, 0.000000, 0.091398, 0.000\textasciitilde{}}
\CommentTok{\#\textgreater{} $ ListPriceDiff  \textless{}dbl\textgreater{} 0.24, 0.24, 0.23, 0.00, 0.00, 0.30,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ STORE          \textless{}dbl\textgreater{} 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  train/test Split
\end{enumerate}

Q: Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.

A: Since this is my first time seeing this dataset, here is my quick overview: The OJ dataset contains 1,070 purchases of two brands of orange juice (`Citrus Hill' or `Minute Maid'), captured in the values of the Purchase variable (CH or MM). The remaining 17 predictors are characteristics of the customer, product, store, etc. Throughout this question we are basically tasked with predicting which orange juice the customer purchased based on these statistics.

I create train and test below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{train\_index }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(OJ), }\DecValTok{800}\NormalTok{)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ OJ[train\_index, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ OJ[}\SpecialCharTok{{-}}\NormalTok{train\_index, ]}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Classification Tree
\end{enumerate}

Q: Fit a tree to the training data, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics about the tree, and describe the results obtained. What is the training error rate? How many terminal nodes does the tree have?

A: The classification tree has 7 terminal nodes and a training error rate of 18.38\%.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree\_model }\OtherTok{\textless{}{-}} \FunctionTok{tree}\NormalTok{(Purchase }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., train)}
\FunctionTok{summary}\NormalTok{(tree\_model)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Classification tree:}
\CommentTok{\#\textgreater{} tree(formula = Purchase \textasciitilde{} ., data = train)}
\CommentTok{\#\textgreater{} Variables actually used in tree construction:}
\CommentTok{\#\textgreater{} [1] "LoyalCH"       "PriceDiff"     "ListPriceDiff"}
\CommentTok{\#\textgreater{} Number of terminal nodes:  9 }
\CommentTok{\#\textgreater{} Residual mean deviance:  0.7347 = 581.1 / 791 }
\CommentTok{\#\textgreater{} Misclassification error rate: 0.1662 = 133 / 800}
\end{Highlighting}
\end{Shaded}

Despite there being 17 predictors in the dataset, only three were used in splits. These were:

\begin{verbatim}
LoyalCH - Customer brand loyalty for CH
PriceDiff - Sale price of MM less sale price of CH
DiscCH - Discount offered for CH
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  tree() - Text Interpretation
\end{enumerate}

Q: Type in the name of the tree object in order to get a detailed text output. Pick one of the terminal nodes, and interpret the information displayed.

A: I print the text output below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree\_model}
\CommentTok{\#\textgreater{} node), split, n, deviance, yval, (yprob)}
\CommentTok{\#\textgreater{}       * denotes terminal node}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  1) root 800 1068.00 CH ( 0.61250 0.38750 )  }
\CommentTok{\#\textgreater{}    2) LoyalCH \textless{} 0.5036 346  412.40 MM ( 0.28324 0.71676 )  }
\CommentTok{\#\textgreater{}      4) LoyalCH \textless{} 0.280875 164  125.50 MM ( 0.12805 0.87195 )  }
\CommentTok{\#\textgreater{}        8) LoyalCH \textless{} 0.0356415 56   10.03 MM ( 0.01786 0.98214 ) *}
\CommentTok{\#\textgreater{}        9) LoyalCH \textgreater{} 0.0356415 108  103.50 MM ( 0.18519 0.81481 ) *}
\CommentTok{\#\textgreater{}      5) LoyalCH \textgreater{} 0.280875 182  248.00 MM ( 0.42308 0.57692 )  }
\CommentTok{\#\textgreater{}       10) PriceDiff \textless{} 0.05 71   67.60 MM ( 0.18310 0.81690 ) *}
\CommentTok{\#\textgreater{}       11) PriceDiff \textgreater{} 0.05 111  151.30 CH ( 0.57658 0.42342 ) *}
\CommentTok{\#\textgreater{}    3) LoyalCH \textgreater{} 0.5036 454  362.00 CH ( 0.86344 0.13656 )  }
\CommentTok{\#\textgreater{}      6) PriceDiff \textless{} {-}0.39 31   40.32 MM ( 0.35484 0.64516 )  }
\CommentTok{\#\textgreater{}       12) LoyalCH \textless{} 0.638841 10    0.00 MM ( 0.00000 1.00000 ) *}
\CommentTok{\#\textgreater{}       13) LoyalCH \textgreater{} 0.638841 21   29.06 CH ( 0.52381 0.47619 ) *}
\CommentTok{\#\textgreater{}      7) PriceDiff \textgreater{} {-}0.39 423  273.70 CH ( 0.90071 0.09929 )  }
\CommentTok{\#\textgreater{}       14) LoyalCH \textless{} 0.705326 135  143.00 CH ( 0.77778 0.22222 )  }
\CommentTok{\#\textgreater{}         28) ListPriceDiff \textless{} 0.255 67   89.49 CH ( 0.61194 0.38806 ) *}
\CommentTok{\#\textgreater{}         29) ListPriceDiff \textgreater{} 0.255 68   30.43 CH ( 0.94118 0.05882 ) *}
\CommentTok{\#\textgreater{}       15) LoyalCH \textgreater{} 0.705326 288   99.77 CH ( 0.95833 0.04167 ) *}
\end{Highlighting}
\end{Shaded}

Choosing node 11), which is a terminal node as it is marked by a *:

First the root node: 1) root 800 1064.00 CH ( 0.61750 0.38250 )

This means that, at the root node, there are 800 observations, the deviance is 1064.00, the overall prediction is CH and the split is 61.75\% CH vs 38.25\% MM.

We can see that, from the root node, three splits take place to produce the terminal node labelled by 11):

\begin{verbatim}
A split at LoyalCH = 0.5036
A split at LoyalCH = 0.142213
A split at PriceDiff = 0.235

 1) root 800 1064.00 CH ( 0.61750 0.38250 )  
   2) LoyalCH < 0.5036 354  435.50 MM ( 0.30508 0.69492 )  
     4) LoyalCH < 0.142213 100   45.39 MM ( 0.06000 0.94000 ) *
     5) LoyalCH > 0.142213 254  342.20 MM ( 0.40157 0.59843 )  
      10) PriceDiff < 0.235 136  153.00 MM ( 0.25000 0.75000 ) *
      11) PriceDiff > 0.235 118  160.80 CH ( 0.57627 0.42373 ) *
\end{verbatim}

Node 11) is therefore the subset of purchases where 0.142213 \textless{} LoyalCH \textless{} 0.5036 and PriceDiff \textgreater{} 0.235. The overall prediction is CH, and the node seems quite impure with 57.627\% CH vs 42.373\% MM.

There are 118 observations in the node, and from the percentages above we know that 68/118 are CH and 50/118 are MM (demonstrated below).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(LoyalCH }\SpecialCharTok{\textless{}} \FloatTok{0.5036}\NormalTok{, }
\NormalTok{         LoyalCH }\SpecialCharTok{\textgreater{}} \FloatTok{0.142213}\NormalTok{, }
\NormalTok{         PriceDiff }\SpecialCharTok{\textgreater{}} \FloatTok{0.235}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(Purchase) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{table}\NormalTok{()}
\CommentTok{\#\textgreater{} Purchase}
\CommentTok{\#\textgreater{} CH MM }
\CommentTok{\#\textgreater{} 57 54}
\end{Highlighting}
\end{Shaded}

Based on the formula on page 325 for the overall deviance of a classification tree \[ (−2∑m∑knmklog(p^mk))\] where the overall deviance sum is over m regions (terminal nodes). We calculate can the deviance of node 11) only using the code below:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{68} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\DecValTok{68}\SpecialCharTok{/}\DecValTok{118}\NormalTok{) }\SpecialCharTok{+} \DecValTok{50} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\DecValTok{50}\SpecialCharTok{/}\DecValTok{118}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 160.8262}
\end{Highlighting}
\end{Shaded}

tree() reports the number as 160.80, and testing with other nodes revealed this is because it's rounding the result to 4 significant figures.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Plotting
\end{enumerate}

Q: Create a plot of the tree, and interpret the results.

A:
LoyalCH is certainly the most important variable (the top 3 nodes all split on this variable), followed by PriceDiff and DiscCH. We can see node 11) is the third terminal node (from left → right).

LoyalCH ranges from 0 to 1, so the first split sends those less loyal to Citrus Hill (CH) orange juice to the left and those more loyal to the right:

plot(tree\_model)
text(tree\_model, pretty = 0, cex = 0.7)

Those that scored lowest in Citrus Hill loyalty (LoyalCH \textless{} 0.142213) were predicted to buy Minute Maid (MM), which isn't surprising. Those that were slightly more loyal to CH (0.142213 \textless{} LoyalCH \textless{} 0.5036) would still buy MM if it wasn't too much more expensive (PriceDiff \textless{} 0.235), but if the price difference is large enough (CH was much cheaper) they could end up purchasing CH.

Those on the far-right terminal node are the most loyal to CH (LoyalCH \textgreater{} 0.705699), so it should be unsurprising that this is their predicted purchase. Those with slightly lower brand loyalty (0.5036 \textless{} LoyalCH \textless{} 0.705699) would still purchase CH if it was much cheaper (PriceDiff \textgreater{} 0.25), or if it wasn't but was sufficiently discounted (PriceDiff \textless{} 0.25 \& DiscCH \textgreater{} 0.15). For those cases where CH wasn't much cheaper (PriceDiff \textless{} 0.25) and wasn't sufficiently discounted (DiscCH \textless{} 0.15), the predicted purchase actually ended up being MM.

This was a much more detailed explanation, but this could be summarized at a much higher level in the following way: people go with the brand they are more loyal towards, but there are some edge cases (based on discounts and the prices relative to one another) that can sway people against their usual brand loyalties.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Test Error
\end{enumerate}

Q: Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test error rate?

A:

Here is the confusion matrix for the unpruned regression tree:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree\_model, test, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(test\_pred, }\AttributeTok{test\_actual =}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{Purchase)}
\CommentTok{\#\textgreater{}          test\_actual}
\CommentTok{\#\textgreater{} test\_pred  CH  MM}
\CommentTok{\#\textgreater{}        CH 148  32}
\CommentTok{\#\textgreater{}        MM  15  75}
\end{Highlighting}
\end{Shaded}

\hypertarget{test_actual}{%
\section{test\_actual}\label{test_actual}}

\hypertarget{test_pred-ch-mm}{%
\section{test\_pred CH MM}\label{test_pred-ch-mm}}

\hypertarget{ch-125-32}{%
\section{CH 125 32}\label{ch-125-32}}

\hypertarget{mm-34-79}{%
\section{MM 34 79}\label{mm-34-79}}

The test error rate corresponding to it:

1 - mean(test\_pred == test\$Purchase)

\hypertarget{section}{%
\section{{[}1{]} 0.2444444}\label{section}}

CH was the most common orange juice in train so, for comparison, a baseline classifier (that predicted CH for all observations in test) would have the following error rate:

1 - mean(test\$Purchase == ``CH'')

\hypertarget{section-1}{%
\section{{[}1{]} 0.4111111}\label{section-1}}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Cost-Complexity Pruning
\end{enumerate}

Q: Apply the cv.tree() function to the training set in order to determine the optimal tree size.

A:

Since our goal appears to be low test error, I specify FUN = prune.misclass. This indicates that we want the classification error rate to guide the cross-validation and pruning process, rather than the default for the cv.tree() function, which is deviance.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{cv\_tree\_model }\OtherTok{\textless{}{-}} \FunctionTok{cv.tree}\NormalTok{(tree\_model, }\AttributeTok{K =} \DecValTok{10}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ prune.misclass)}
\NormalTok{cv\_tree\_model}
\CommentTok{\#\textgreater{} $size}
\CommentTok{\#\textgreater{} [1] 9 6 5 3 2 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $dev}
\CommentTok{\#\textgreater{} [1] 149 149 149 173 172 310}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $k}
\CommentTok{\#\textgreater{} [1]  {-}Inf   0.0   1.0   8.5   9.0 150.0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $method}
\CommentTok{\#\textgreater{} [1] "misclass"}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} attr(,"class")}
\CommentTok{\#\textgreater{} [1] "prune"         "tree.sequence"}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  CV Error Plot
\end{enumerate}

Q: Produce a plot with tree size on the x-axis and cross-validated classification error rate on the y-axis.

A:

The plot is below. Note that cv\_tree\_model\(size is the number of terminal nodes (so 1 means it is just the root node with no splits), and cv_tree_model\)dev gives the total number of errors made from the out-of-fold predictions during cross-validation (only because we specified FUN = prune.misclass - omitting this would mean this reports the deviance). From this we can obtain the cross-validation error rate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size =}\NormalTok{ cv\_tree\_model}\SpecialCharTok{$}\NormalTok{size, }\AttributeTok{CV\_Error =}\NormalTok{ cv\_tree\_model}\SpecialCharTok{$}\NormalTok{dev }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(train)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{min\_CV\_Error =} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{min}\NormalTok{(CV\_Error) }\SpecialCharTok{==}\NormalTok{ CV\_Error)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ size, }\AttributeTok{y =}\NormalTok{ CV\_Error)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{col =} \StringTok{"grey55"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{2}\NormalTok{, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{col =} \FunctionTok{factor}\NormalTok{(min\_CV\_Error))) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{7}\NormalTok{), }\AttributeTok{minor\_breaks =} \ConstantTok{NULL}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{labels =}\NormalTok{ scales}\SpecialCharTok{::}\FunctionTok{percent\_format}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"deepskyblue3"}\NormalTok{, }\StringTok{"green"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"OJ Dataset {-} Classification Tree"}\NormalTok{,}
       \AttributeTok{subtitle =} \StringTok{"Selecting tree \textquotesingle{}size\textquotesingle{} (\# of terminal nodes) using cross{-}validation"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Tree Size"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"CV Error"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{121-trees_no_9_files/figure-latex/unnamed-chunk-10-1.pdf}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Best Tree - CV Error
\end{enumerate}

Q: Which tree size corresponds to the lowest cross-validated classification error rate?

A:

Of the sequence of trees generated, trees of sizes 4 and 7 have the same cross-validation error. It makes sense to select the more parsimonious model here with 4 terminal nodes.

\begin{enumerate}
\def\labelenumi{(\roman{enumi})}
\tightlist
\item
  Best Tree - Selecting
\end{enumerate}

Q: Produce a pruned tree corresponding to the optimal tree size obtained using cross-validation. If cross-validation does not lead to selection of a pruned tree, then create a pruned tree with five terminal nodes.

A:

I produce the tree with 4 terminal nodes. Interestingly we have the same cross-validation error as the full tree with 7 terminal nodes, but have only split on LoyalCH to achieve this. This would have the added benefit of simplifying the interpretation in part (d).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pruned\_tree\_model }\OtherTok{\textless{}{-}} \FunctionTok{prune.tree}\NormalTok{(tree\_model, }\AttributeTok{best =} \DecValTok{4}\NormalTok{)}
\NormalTok{pruned\_tree\_model}
\CommentTok{\#\textgreater{} node), split, n, deviance, yval, (yprob)}
\CommentTok{\#\textgreater{}       * denotes terminal node}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} 1) root 800 1068.00 CH ( 0.61250 0.38750 )  }
\CommentTok{\#\textgreater{}   2) LoyalCH \textless{} 0.5036 346  412.40 MM ( 0.28324 0.71676 )  }
\CommentTok{\#\textgreater{}     4) LoyalCH \textless{} 0.280875 164  125.50 MM ( 0.12805 0.87195 ) *}
\CommentTok{\#\textgreater{}     5) LoyalCH \textgreater{} 0.280875 182  248.00 MM ( 0.42308 0.57692 ) *}
\CommentTok{\#\textgreater{}   3) LoyalCH \textgreater{} 0.5036 454  362.00 CH ( 0.86344 0.13656 )  }
\CommentTok{\#\textgreater{}     6) PriceDiff \textless{} {-}0.39 31   40.32 MM ( 0.35484 0.64516 ) *}
\CommentTok{\#\textgreater{}     7) PriceDiff \textgreater{} {-}0.39 423  273.70 CH ( 0.90071 0.09929 ) *}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Training Error Comparison
\end{enumerate}

Q: Compare the training error rates between the pruned and unpruned trees. Which is higher?

A:
Here is the training error for the unpruned tree (7 terminal nodes):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{predict}\NormalTok{(tree\_model, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{) }\SpecialCharTok{!=}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{Purchase)}
\CommentTok{\#\textgreater{} [1] 0.16625}
\end{Highlighting}
\end{Shaded}

The same for the pruned tree (4 terminal nodes):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{predict}\NormalTok{(pruned\_tree\_model, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{) }\SpecialCharTok{!=}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{Purchase)}
\CommentTok{\#\textgreater{} [1] 0.18875}
\end{Highlighting}
\end{Shaded}

The training error for the pruned tree is higher. This isn't surprising - we would expect the training error of a tree to monotonically decrease as its flexibility (number of splits) increases.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{10}
\tightlist
\item
  Test Error Comparison
\end{enumerate}

Q: Compare the test error rates between the pruned and unpruned trees. Which is higher?

A:

The test error for the unpruned tree:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{predict}\NormalTok{(tree\_model, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ test) }\SpecialCharTok{!=}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{Purchase)}
\CommentTok{\#\textgreater{} [1] 0.1740741}
\end{Highlighting}
\end{Shaded}

The same for the pruned tree:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{predict}\NormalTok{(pruned\_tree\_model, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ test) }\SpecialCharTok{!=}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{Purchase)}
\CommentTok{\#\textgreater{} [1] 0.2}
\end{Highlighting}
\end{Shaded}

Now the order has reversed and the error is higher for the unpruned tree.

It is interesting that the cross-validation errors were in fact equal but the test error is noticeably lower for the simpler tree. A lot of this probably comes from random variability when working with a small dataset; using a different random state for the CV folds and train/test split would likely change all of these results (particularly because decision trees are such high-variance approaches).

\hypertarget{project-e1}{%
\chapter{Project (E1)}\label{project-e1}}

\hypertarget{a-project-to-call-your-own}{%
\section{A project to call your own}\label{a-project-to-call-your-own}}

Pick a dataset, any dataset\ldots{}

\ldots and do something with it. That is your first Analytics 2 project. Make us both proud, in a nutshell. More details below.

\hypertarget{may-be-too-long-but-please-do-read}{%
\section{May be too long, but please do read}\label{may-be-too-long-but-please-do-read}}

This project for this class will consist of analysis on a dataset of your own
choosing. \textbf{Please make sure I am ok with your choice.} The dataset may already exist,
or you may collect your own data using a
survey or by conducting an experiment. You can choose the data based on your interests
or based on work in other courses or research projects. The goal of this project is for
you to demonstrate proficiency in the techniques we have covered in this class (and
beyond, if you like) and apply them to a novel dataset in a meaningful way.

\hypertarget{data}{%
\section{Data}\label{data}}

In order for you to have the greatest chance of success with this project it is important that
you choose a manageable dataset. This means that the data should be readily accessible and large
enough that multiple relationships can be explored. As such, your dataset must have at least 50
observations and between 10 to 20 variables (exceptions can be made but you must speak with me
first). The dataset's variables should include categorical variables, discrete numerical
variables, and continuous numerical variables.

All analyses must be done in RStudio. If you are using a dataset that comes in a format that
we haven't encountered in class, make sure that you are able to load it into RStudio as this
can be tricky depending on the source. If you are having trouble ask for help before it is too late.

\emph{Reusing datasets from class:} Do not reuse datasets used in examples / homework in the
class.

\hypertarget{components}{%
\section{Components}\label{components}}

\hypertarget{project-proposal}{%
\subsection{Project proposal}\label{project-proposal}}

This is a draft of the introduction section of your project as well as a
data analysis plan and your dataset. Each section should be no more than 1
page (excluding figures). You can check a print preview to confirm length.

\begin{quote}
Your write up and all analysis including visuals must be done using R Markdown.
\end{quote}

\hypertarget{section-1---introduction}{%
\subsubsection{Section 1 - Introduction:}\label{section-1---introduction}}

The introduction should introduce your general research
question and your data (where it came from, how it was collected, what
are the cases, what are the variables, etc.).

\hypertarget{section-2---data-analysis-plan}{%
\subsubsection{Section 2 - Data analysis plan:}\label{section-2---data-analysis-plan}}

The data analysis plan should include:

\begin{itemize}
\tightlist
\item
  The outcome (dependent, response, Y) and predictor (independent, explanatory, X)
  variables you will use to answer your question.
\item
  The comparison groups you will use, if applicable.
\item
  Very preliminary exploratory data analysis, including some summary statistics and
  visualizations, along with some explanation on how they help you learn more about your data.
  (You can add to these later as you work on your project..)
\item
  The statistical method(s) that you believe will be useful in answering your question(s).
  (You can update these later as you work on your project.)
\item
  Ideally you will use at least two out of these options: tree methods, linear regression,
  and classification (like logistic regression).
\item
  What results from these specific statistical methods are needed to support your
  hypothesized answer?
\end{itemize}

\hypertarget{section-3---data}{%
\subsubsection{Section 3 - Data:}\label{section-3---data}}

In yuor write up, include enough details that I understand what your raw data looked like
and included.

\hypertarget{project}{%
\subsection{Project}\label{project}}

\hypertarget{write-up}{%
\subsubsection{Write up}\label{write-up}}

After providing the description of your dataset and research question in the
introduction use the remainder of your write up to showcase how you have arrived at
an answer / answers to your question using any techniques we have learned in this
class (and some beyond, if you're feeling adventurous). The goal is not to do an exhaustive
data analysis i.e., do not calculate every statistic and procedure you have
learned for every variable, but rather let me know that you are proficient at
asking meaningful questions and answering them with results of data analysis, that
you are proficient in using R, and that you are proficient at interpreting and
presenting the results. Focus on methods that help you begin to answer your research
questions. You do not have to apply every statistical procedure we learned.
Also pay attention to your presentation. Neatness, coherency, and clarity will count.

Your write up must also include a one to two page conclusion and discussion.
This will require a summary of what you have learned about your research
question along with statistical arguments supporting your conclusions. Also
critique your own methods and provide suggestions for improving your analysis.
Issues pertaining to the reliability and validity of your data, and
appropriateness of the statistical analysis should be discussed here. A
paragraph on what you would do differently if you were able to start over
with the project or what you would do next if you were going to continue
work on the project should also be included.

\begin{quote}
The project is very open ended. You should create some kind of compelling
visualization(s) of this data in R.
\end{quote}

There is no limit on what tools or packages you may use, but sticking to packages we learned in class (ISLR and R4DS)
is required. You do not need to visualize all of the data at once. A single high quality
visualization will receive a much higher grade than a large number of poor quality
visualizations.

Before you finalize your write up, make sure your chunks are turned off
with \texttt{echo\ =\ FALSE}. \textbf{Exception:} If you want to
highlight something specific about a piece of code, you're welcomed to show
that portion. {[}See below: I will also want a copy of the raw .Rmd file not just the html output.{]}

You can add sections as you see fit to the project but make sure
you have a section called Introduction at the beginning and a section called
Conclusion at the end. The rest is up to you!

\hypertarget{presentation}{%
\subsubsection{Presentation}\label{presentation}}

10 minutes maximum.

You can use any software you like for your final presentation, including R Markdown
to create your slides. There isn't a limit to how many slides you can use, just a
time limit (10 minutes total). Perhaps try \texttt{ioslides} or \texttt{beamer}. Your presentation
should not just be an account of everything you
tried (``then we did this, then we did this, etc.''), instead it should convey what
choices you made, and why, and what you found.

\hypertarget{delivarables}{%
\subsubsection{Delivarables}\label{delivarables}}

Your submission should include

\begin{itemize}
\tightlist
\item
  RMarkdown file (formatted to clearly present all of your code and results)
\item
  HTML file
\item
  Dataset(s) (in csv or RData format, in a \texttt{/data} folder)
\item
  Presentation (if using Keynote/PowerPoint/Google Slides, export to PDF and put in repo, in a \texttt{/presentation} folder)
\end{itemize}

Style and format does count for this assignment, so please take the time to make
sure everything looks good and your data and code are properly formated.

\hypertarget{grading}{%
\section{Grading}\label{grading}}

\begin{longtable}[]{@{}ll@{}}
\toprule()
Total & 100 pts \\
\midrule()
\endhead
Introduction & 20 pts \\
Data analysis plan & 20 pts \\
Data Methods and code quality & 50 pts \\
Organization & 10 pts \\
\bottomrule()
\end{longtable}

Grading of the project will take into account the following:

\begin{itemize}
\tightlist
\item
  Content - What is the quality of research and/or policy question and relevancy
  of data to those questions?
\item
  Correctness - Are statistical procedures carried out and explained correctly?
\item
  Writing and Presentation - What is the quality of the statistical presentation,
  writing, and explanations?
\item
  Creativity and Critical Thought - Is the project carefully thought out? Are the
  limitations carefully considered? Does it appear that time and effort went into
  the planning and implementation of the project?
\end{itemize}

A general breakdown of scoring is as follows:

\begin{itemize}
\tightlist
\item
  90\%-100\% - Outstanding effort. Student understands how to apply all statistical
  concepts, can put the results into a cogent argument, can identify weaknesses in
  the argument, and can clearly communicate the results to others.
\item
  80\%-89\% - Good effort. Student understands most of the concepts, puts together
  an adequate argument, identifies some weaknesses of their argument, and communicates
  most results clearly to others.
\item
  70\%-79\% - Passing effort. Student has misunderstanding of concepts in several
  areas, has some trouble putting results together in a cogent argument, and communication
  of results is sometimes unclear.
\item
  60\%-69\% - Struggling effort. Student is making some effort, but has misunderstanding
  of many concepts and is unable to put together a cogent argument. Communication
  of results is unclear.
\item
  Below 60\% - Student is not making a sufficient effort.
\end{itemize}

\textbf{Late penalty:}

\begin{itemize}
\tightlist
\item
  Late, but within 24 hours of due date/time: -20\% (only applies to written portion, there is no option to do your presentation later)
\item
  Any later: no credit
\end{itemize}

  \bibliography{book.bib,packages.bib}

\end{document}
